[[["60f3226f-f447-4c23-9c37-db001113bb79",{"pageContent":"Generative artificial intelligence or generative AI is a type of artificial intelligence (AI) system capable of generating text, images, or other media in response to prompts. Generative AI models learn the patterns and structure of their input training data, and then generate new data that has similar characteristics.Notable generative AI systems include ChatGPT (and its variant Bing Chat), a chatbot built by OpenAI using their GPT-3 and GPT-4 foundational large language models, and Bard, a chatbot built by Google using their LaMDA foundation model.\nOther generative AI models include artificial intelligence art systems such as Stable Diffusion, Midjourney, and DALL-E.Generative AI has potential applications across a wide range of industries, including art, writing, software development, healthcare, finance, gaming, marketing, and fashion.","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_artificial_intelligence","loc":{"lines":{"from":1,"to":2}}}}],["73e65637-a6e8-4f4c-bd90-b7518c3261c8",{"pageContent":"Investment in generative AI surged during the early 2020s, with large companies such as Microsoft, Google, and Baidu as well as numerous smaller firms developing generative AI models. However, there are also concerns about the potential misuse of generative AI, such as in creating fake news or deepfakes, which can be used to deceive or manipulate people.","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_artificial_intelligence","loc":{"lines":{"from":3,"to":3}}}}],["fb97d150-f31a-4f44-b941-3f8315c3a816",{"pageContent":"== History ==","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_artificial_intelligence","loc":{"lines":{"from":6,"to":6}}}}],["65974fa5-1750-4573-94c4-4f059a65647d",{"pageContent":"Since its founding, the field of machine learning has used statistical models, including generative models, to model and predict data. Beginning in the late 2000s, the emergence of deep learning drove progress and research in image and video processing, text analysis, speech recognition, and other tasks. However, most deep neural networks were trained as discriminative models performing classification tasks such as convolutional neural network-based image classification.\nIn 2014, advancements such as the variational autoencoder and generative adversarial network produced the first practical deep neural networks capable of learning generative, rather than discriminative, models of complex data such as images. These deep generative models were the first able to output not only class labels for images, but to output entire images.","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_artificial_intelligence","loc":{"lines":{"from":8,"to":9}}}}],["bbcb70df-bfa1-4506-b372-26a66b88a8f1",{"pageContent":"In 2017, the Transformer network enabled advancements in generative models, leading to the first Generative pre-trained transformer in 2018. This was followed in 2019 by GPT-2 which demonstrated the ability to generalize unsupervised to many different tasks as a Foundation model.In 2021, the release of DALL-E, a transformer-based pixel generative model, followed by Midjourney and Stable Diffusion marked the emergence of practical high quality artificial intelligence art from natural language prompts.\nIn 2023, GPT-4 was released. A team from Microsoft Research concluded that \"it could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence (AGI) system\".","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_artificial_intelligence","loc":{"lines":{"from":10,"to":11}}}}],["b930acf7-4373-4670-babe-ac7b5a46028d",{"pageContent":"== Modalities ==","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_artificial_intelligence","loc":{"lines":{"from":14,"to":14}}}}],["cccb7dcd-7476-4a00-9d37-799ce6d89504",{"pageContent":"A generative AI system is constructed by applying unsupervised or self-supervised machine learning to a data set. The capabilities of a generative AI system depend on the modality or type of the data set used.\nGenerative AI can be either unimodal or multimodal; unimodal systems take only one type of input, whereas multimodal systems can take more than one type of input. For example, one version of OpenAI's GPT-4 accepts both text and image inputs.\nText: Generative AI systems trained on words or word tokens include GPT-3, LaMDA, LLaMA, BLOOM, GPT-4, and others (see List of large language models). They are capable of natural language processing, machine translation, and natural language generation and can be used as foundation models for other tasks. Data sets include BookCorpus, Wikipedia, and others (see List of text corpora).","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_artificial_intelligence","loc":{"lines":{"from":16,"to":18}}}}],["124dbacd-055d-4ec7-bb3f-e328fed84868",{"pageContent":"Code: In addition to natural language text, large language models can be trained on programming language text, allowing them to generate source code for new computer programs. Examples include OpenAI Codex.\nImages: Generative AI systems trained on sets of images with text captions include Imagen, DALL-E, Midjourney, Stable Diffusion and others (see Artificial intelligence art, Generative art, Synthetic media). They are commonly used for text-to-image generation and neural style transfer. Datasets include LAION-5B and others (See Datasets in computer vision).\nMolecules: Generative AI systems can be trained on sequences of amino acids or molecular representations such as SMILES representing DNA or proteins. These systems, such as AlphaFold, are used for protein structure prediction and drug discovery. Datasets include various biological datasets.","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_artificial_intelligence","loc":{"lines":{"from":19,"to":21}}}}],["8d9205e3-3a99-4072-bf27-6b7ad7d4031d",{"pageContent":"Music: Generative AI systems such as MusicLM can be trained on the audio waveforms of recorded music along with text annotations, in order to generate new musical samples based on text descriptions such as a calming violin melody backed by a distorted guitar riff.\nVideo: Generative AI trained on annotated video can generate temporally-coherent video clips. Examples include Gen1 by RunwayML and Make-A-Video by Meta Platforms.\nRobot Actions: Generative AI trained on the motions of a robotic system can generate new trajectories for motion planning. For example, UniPi from Google Research uses prompts like pick up blue bowl or wipe plate with yellow sponge to control movements of a robot arm.","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_artificial_intelligence","loc":{"lines":{"from":22,"to":24}}}}],["dc59c82c-4fa0-4c35-b4fe-dc8515405240",{"pageContent":"== See also ==\nComputational creativity – Multidisciplinary endeavour\nArtificial general intelligence – Hypothetical human-level or stronger AI\nArtificial imagination – Artificial simulation of human imagination\nArtificial intelligence art – Machine application of knowledge of human aesthetic expressions\nMusic and artificial intelligence – Common subject in the International Computer Music Conference\nGenerative adversarial network – Deep learning method\nGenerative pre-trained transformer – Type of large language model\nLarge language model – Language model consisting of a neural network\n\n\n== References ==","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_artificial_intelligence","loc":{"lines":{"from":27,"to":38}}}}],["5f3bdfa1-2799-4153-bb28-818e666a9fa0",{"pageContent":"A generative adversarial network (GAN) is a class of machine learning frameworks and a prominent framework for approaching generative AI. The concept was initially developed by Ian Goodfellow and his colleagues in June 2014. In a GAN, two neural networks contest with each other in the form of a zero-sum game, where one agent's gain is another agent's loss.","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":1,"to":1}}}}],["94962890-afdc-4976-9d6d-cd0c30372152",{"pageContent":"Given a training set, this technique learns to generate new data with the same statistics as the training set. For example, a GAN trained on photographs can generate new photographs that look at least superficially authentic to human observers, having many realistic characteristics. Though originally proposed as a form of generative model for unsupervised learning, GANs have also proved useful for semi-supervised learning, fully supervised learning, and reinforcement learning.The core idea of a GAN is based on the \"indirect\" training through the discriminator, another neural network that can tell how \"realistic\" the input seems, which itself is also being updated dynamically. This means that the generator is not trained to minimize the distance to a specific image, but rather to fool the discriminator. This enables the model to learn in an unsupervised manner.\nGANs are similar to mimicry in evolutionary biology, with an evolutionary arms race between both networks.","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":2,"to":3}}}}],["a4871728-badd-4266-867d-c1c9af7344f2",{"pageContent":"== Definition ==","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":6,"to":6}}}}],["a223b309-ab2f-4c7e-924e-369932a1d963",{"pageContent":"=== Mathematical ===\nThe original GAN is defined as the following game:\nEach probability space \n  \n    \n      \n        (\n        Ω\n        ,\n        \n          μ\n          \n            r\n            e\n            f\n          \n        \n        )\n      \n    \n    {\\displaystyle (\\Omega ,\\mu _{ref})}\n   defines a GAN game.\nThere are 2 players: generator and discriminator.\nThe generator's strategy set is \n  \n    \n      \n        \n          \n            P\n          \n        \n        (\n        Ω\n        )\n      \n    \n    {\\displaystyle {\\mathcal {P}}(\\Omega )}\n  , the set of all probability measures \n  \n    \n      \n        \n          μ\n          \n            G\n          \n        \n      \n    \n    {\\displaystyle \\mu _{G}}\n   on \n  \n    \n      \n        Ω\n      \n    \n    {\\displaystyle \\Omega }\n  .\nThe discriminator's strategy set is the set of Markov kernels \n  \n    \n      \n        \n          μ\n          \n            D\n          \n        \n        :\n        Ω\n        →\n        \n          \n            P\n          \n        \n        [\n        0\n        ,\n        1\n        ]","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":9,"to":91}}}}],["4d0f93ab-8b2a-4b72-b093-62cd746b0e21",{"pageContent":"μ\n          \n            D\n          \n        \n        :\n        Ω\n        →\n        \n          \n            P\n          \n        \n        [\n        0\n        ,\n        1\n        ]\n      \n    \n    {\\displaystyle \\mu _{D}:\\Omega \\to {\\mathcal {P}}[0,1]}\n  , where \n  \n    \n      \n        \n          \n            P\n          \n        \n        [\n        0\n        ,\n        1\n        ]\n      \n    \n    {\\displaystyle {\\mathcal {P}}[0,1]}\n   is the set of probability measures on \n  \n    \n      \n        [\n        0\n        ,\n        1\n        ]\n      \n    \n    {\\displaystyle [0,1]}\n  .\nThe GAN game is a zero-sum game, with objective function\nThe generator aims to minimize the objective, and the discriminator aims to maximize the objective.","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":91,"to":143}}}}],["fc734936-19b5-4a08-a854-4881a5d4f2ff",{"pageContent":"The generator's task is to approach \n  \n    \n      \n        \n          μ\n          \n            G\n          \n        \n        ≈\n        \n          μ\n          \n            r\n            e\n            f\n          \n        \n      \n    \n    {\\displaystyle \\mu _{G}\\approx \\mu _{ref}}\n  , that is, to match its own output distribution as closely as possible to the reference distribution. The discriminator's task is to output a value close to 1 when the input appears to be from the reference distribution, and to output a value close to 0 when the input looks like it came from the generator distribution.","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":145,"to":167}}}}],["d45d051e-35f3-43ec-a070-8e270d421973",{"pageContent":"=== In practice ===","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":170,"to":170}}}}],["71778adf-0451-46c7-a29d-597c0b26eda5",{"pageContent":"The generative network generates candidates while the discriminative network evaluates them. The contest operates in terms of data distributions. Typically, the generative network learns to map from a latent space to a data distribution of interest, while the discriminative network distinguishes candidates produced by the generator from the true data distribution. The generative network's training objective is to increase the error rate of the discriminative network (i.e., \"fool\" the discriminator network by producing novel candidates that the discriminator thinks are not synthesized (are part of the true data distribution)).A known dataset serves as the initial training data for the discriminator. Training involves presenting it with samples from the training dataset until it achieves acceptable accuracy. The generator is trained based on whether it succeeds in fooling the discriminator. Typically, the generator is seeded with randomized input that is sampled from a predefined latent space (e.g. a multivariate normal distribution). Thereafter, candidates synthesized by the generator are evaluated by the discriminator. Independent","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":171,"to":171}}}}],["b6a288d1-5e41-4a5c-9168-abd74fef2174",{"pageContent":"is seeded with randomized input that is sampled from a predefined latent space (e.g. a multivariate normal distribution). Thereafter, candidates synthesized by the generator are evaluated by the discriminator. Independent backpropagation procedures are applied to both networks so that the generator produces better samples, while the discriminator becomes more skilled at flagging synthetic samples. When used for image generation, the generator is typically a deconvolutional neural network, and the discriminator is a convolutional neural network.","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":171,"to":171}}}}],["595b50f9-1aa2-420e-87ac-92247a0278d2",{"pageContent":"=== Relation to other statistical machine learning methods ===\nGANs are implicit generative models, which means that they do not explicitly model the likelihood function nor provide a means for finding the latent variable corresponding to a given sample, unlike alternatives such as flow-based generative model.\n\nCompared to fully visible belief networks such as WaveNet and PixelRNN and autoregressive models in general, GANs can generate one complete sample in one pass, rather than multiple passes through the network.\nCompared to Boltzmann machines and nonlinear ICA, there is no restriction on the type of function used by the network.\nSince neural networks are universal approximators, GANs are asymptotically consistent. Variational autoencoders might be universal approximators, but it is not proven as of 2017.\n\n\n== Mathematical properties ==\n\n\n=== Measure-theoretic considerations ===\nThis section provides some of the mathematical theory behind these methods.","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":174,"to":186}}}}],["5dc07edd-6678-4741-b201-83da58e5d18d",{"pageContent":"In modern probability theory based on measure theory, a probability space also needs to be equipped with a σ-algebra. As a result, a more rigorous definition of the GAN game would make the following changes:Each probability space \n  \n    \n      \n        (\n        Ω\n        ,\n        \n          \n            B\n          \n        \n        ,\n        \n          μ\n          \n            r\n            e\n            f\n          \n        \n        )\n      \n    \n    {\\displaystyle (\\Omega ,{\\mathcal {B}},\\mu _{ref})}\n   defines a GAN game.\nThe generator's strategy set is \n  \n    \n      \n        \n          \n            P\n          \n        \n        (\n        Ω\n        ,\n        \n          \n            B\n          \n        \n        )\n      \n    \n    {\\displaystyle {\\mathcal {P}}(\\Omega ,{\\mathcal {B}})}\n  , the set of all probability measures \n  \n    \n      \n        \n          μ\n          \n            G\n          \n        \n      \n    \n    {\\displaystyle \\mu _{G}}\n   on the measure-space \n  \n    \n      \n        (\n        Ω\n        ,\n        \n          \n            B","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":188,"to":257}}}}],["40d16d40-c6b5-4dd4-9d7b-7c3e145bffb6",{"pageContent":"μ\n          \n            G\n          \n        \n      \n    \n    {\\displaystyle \\mu _{G}}\n   on the measure-space \n  \n    \n      \n        (\n        Ω\n        ,\n        \n          \n            B\n          \n        \n        )\n      \n    \n    {\\displaystyle (\\Omega ,{\\mathcal {B}})}\n  .","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":257,"to":281}}}}],["b5cacc6b-5e76-4e7d-9b1d-0f330fc519c0",{"pageContent":"The discriminator's strategy set is the set of Markov kernels \n  \n    \n      \n        \n          μ\n          \n            D\n          \n        \n        :\n        (\n        Ω\n        ,\n        \n          \n            B\n          \n        \n        )\n        →\n        \n          \n            P\n          \n        \n        (\n        [\n        0\n        ,\n        1\n        ]\n        ,\n        \n          \n            B\n          \n        \n        (\n        [\n        0\n        ,\n        1\n        ]\n        )\n        )\n      \n    \n    {\\displaystyle \\mu _{D}:(\\Omega ,{\\mathcal {B}})\\to {\\mathcal {P}}([0,1],{\\mathcal {B}}([0,1]))}\n  , where \n  \n    \n      \n        \n          \n            B\n          \n        \n        (\n        [\n        0\n        ,\n        1\n        ]\n        )\n      \n    \n    {\\displaystyle {\\mathcal {B}}([0,1])}\n   is the Borel σ-algebra on \n  \n    \n      \n        [\n        0\n        ,\n        1\n        ]\n      \n    \n    {\\displaystyle [0,1]}\n  .Since issues of measurability never arise in practice, these will not concern us further.","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":283,"to":363}}}}],["93320cb9-e13c-4604-8d0b-51d316861448",{"pageContent":"=== Choice of the strategy set ===\nIn the most generic version of the GAN game described above, the strategy set for the discriminator contains all Markov kernels \n  \n    \n      \n        \n          μ\n          \n            D\n          \n        \n        :\n        Ω\n        →\n        \n          \n            P\n          \n        \n        [\n        0\n        ,\n        1\n        ]\n      \n    \n    {\\displaystyle \\mu _{D}:\\Omega \\to {\\mathcal {P}}[0,1]}\n  , and the strategy set for the generator contains arbitrary probability distributions \n  \n    \n      \n        \n          μ\n          \n            G\n          \n        \n      \n    \n    {\\displaystyle \\mu _{G}}\n   on \n  \n    \n      \n        Ω\n      \n    \n    {\\displaystyle \\Omega }\n  .\nHowever, as shown below, the optimal discriminator strategy against any \n  \n    \n      \n        \n          μ\n          \n            G\n          \n        \n      \n    \n    {\\displaystyle \\mu _{G}}\n   is deterministic, so there is no loss of generality in restricting the discriminator's strategies to deterministic functions","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":366,"to":428}}}}],["56d278d0-1296-4441-91b4-b7af6771115b",{"pageContent":"G\n          \n        \n      \n    \n    {\\displaystyle \\mu _{G}}\n   is deterministic, so there is no loss of generality in restricting the discriminator's strategies to deterministic functions \n  \n    \n      \n        D\n        :\n        Ω\n        →\n        [\n        0\n        ,\n        1\n        ]\n      \n    \n    {\\displaystyle D:\\Omega \\to [0,1]}\n  . In most applications, \n  \n    \n      \n        D\n      \n    \n    {\\displaystyle D}\n   is a deep neural network function.\nAs for the generator, while \n  \n    \n      \n        \n          μ\n          \n            G\n          \n        \n      \n    \n    {\\displaystyle \\mu _{G}}\n   could theoretically be any computable probability distribution, in practice, it is usually implemented as a pushforward: \n  \n    \n      \n        \n          μ\n          \n            G\n          \n        \n        =\n        \n          μ\n          \n            Z\n          \n        \n        ∘\n        \n          G\n          \n            −\n            1\n          \n        \n      \n    \n    {\\displaystyle \\mu _{G}=\\mu _{Z}\\circ G^{-1}}","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":428,"to":499}}}}],["1aa5138c-8d98-4e27-aa1c-da769836e896",{"pageContent":"μ\n          \n            Z\n          \n        \n        ∘\n        \n          G\n          \n            −\n            1\n          \n        \n      \n    \n    {\\displaystyle \\mu _{G}=\\mu _{Z}\\circ G^{-1}}\n  . That is, start with a random variable \n  \n    \n      \n        z\n        ∼\n        \n          μ\n          \n            Z\n          \n        \n      \n    \n    {\\displaystyle z\\sim \\mu _{Z}}\n  , where \n  \n    \n      \n        \n          μ\n          \n            Z\n          \n        \n      \n    \n    {\\displaystyle \\mu _{Z}}\n   is a probability distribution that is easy to compute (such as the uniform distribution, or the Gaussian distribution), then define a function \n  \n    \n      \n        G\n        :\n        \n          Ω\n          \n            Z\n          \n        \n        →\n        Ω\n      \n    \n    {\\displaystyle G:\\Omega _{Z}\\to \\Omega }\n  . Then the distribution \n  \n    \n      \n        \n          μ\n          \n            G\n          \n        \n      \n    \n    {\\displaystyle \\mu _{G}}\n   is the distribution of \n  \n    \n      \n        G\n        (\n        z","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":499,"to":579}}}}],["cfd8f153-22c0-4cec-a9de-75ca4ca42314",{"pageContent":"μ\n          \n            G\n          \n        \n      \n    \n    {\\displaystyle \\mu _{G}}\n   is the distribution of \n  \n    \n      \n        G\n        (\n        z\n        )\n      \n    \n    {\\displaystyle G(z)}\n  .\nConsequently, the generator's strategy is usually defined as just \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n  , leaving \n  \n    \n      \n        z\n        ∼\n        \n          μ\n          \n            Z\n          \n        \n      \n    \n    {\\displaystyle z\\sim \\mu _{Z}}\n   implicit. In this formalism, the GAN game objective is","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":579,"to":622}}}}],["629b2565-28fe-4068-8d58-9adf2b2cf457",{"pageContent":"=== Generative reparametrization ===\nThe GAN architecture has two main components. One is casting optimization into a game, of form \n  \n    \n      \n        \n          min\n          \n            G\n          \n        \n        \n          max\n          \n            D\n          \n        \n        L\n        (\n        G\n        ,\n        D\n        )\n      \n    \n    {\\displaystyle \\min _{G}\\max _{D}L(G,D)}\n  , which is different from the usual kind of optimization, of form \n  \n    \n      \n        \n          min\n          \n            θ\n          \n        \n        L\n        (\n        θ\n        )\n      \n    \n    {\\displaystyle \\min _{\\theta }L(\\theta )}\n  . The other is the decomposition of \n  \n    \n      \n        \n          μ\n          \n            G\n          \n        \n      \n    \n    {\\displaystyle \\mu _{G}}\n   into \n  \n    \n      \n        \n          μ\n          \n            Z\n          \n        \n        ∘\n        \n          G\n          \n            −\n            1\n          \n        \n      \n    \n    {\\displaystyle \\mu _{Z}\\circ G^{-1}}","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":625,"to":701}}}}],["2cbbb28f-f3b4-4f90-bf67-286bfef326b7",{"pageContent":"μ\n          \n            Z\n          \n        \n        ∘\n        \n          G\n          \n            −\n            1\n          \n        \n      \n    \n    {\\displaystyle \\mu _{Z}\\circ G^{-1}}\n  , which can be understood as a reparametrization trick.\nTo see its significance, one must compare GAN with previous methods for learning generative models, which were plagued with \"intractable probabilistic computations that arise in maximum likelihood estimation and related strategies\".At the same time, Kingma and Welling and Rezende et al. developed the same idea of reparametrization into a general stochastic backpropagation method. Among its first applications was the variational autoencoder.","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":701,"to":718}}}}],["dec4fe99-5be3-46c0-adc0-626e4b5f51ae",{"pageContent":"=== Move order and strategic equilibria ===\nIn the original paper, as well as most subsequent papers, it is usually assumed that the generator moves first, and the discriminator moves second, thus giving the following minimax game:\nIf both the generator's and the discriminator's strategy sets are spanned by a finite number of strategies, then by the minimax theorem,that is, the move order does not matter.\nHowever, since the strategy sets are both not finitely spanned, the minimax theorem does not apply, and the idea of an \"equilibrium\" becomes delicate. To wit, there are the following different concepts of equilibrium:","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":721,"to":724}}}}],["729f83ef-59d8-438d-adc4-97b3af27ab4c",{"pageContent":"Equilibrium when generator moves first, and discriminator moves second:\nEquilibrium when discriminator moves first, and generator moves second:\nNash equilibrium \n  \n    \n      \n        (\n        \n          \n            \n              \n                μ\n                ^\n              \n            \n          \n          \n            D\n          \n        \n        ,\n        \n          \n            \n              \n                μ\n                ^\n              \n            \n          \n          \n            G\n          \n        \n        )\n      \n    \n    {\\displaystyle ({\\hat {\\mu }}_{D},{\\hat {\\mu }}_{G})}\n  , which is stable under simultaneous move order:For general games, these equilibria do not have to agree, or even to exist. For the original GAN game, these equilibria all exist, and are all equal. However, for more general GAN games, these do not necessarily exist, or agree.","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":726,"to":764}}}}],["67007ab0-9000-4889-85eb-deadaaf595be",{"pageContent":"=== Main theorems for GAN game ===\nThe original GAN paper proved the following two theorems:\nInterpretation: For any fixed generator strategy \n  \n    \n      \n        \n          μ\n          \n            G\n          \n        \n      \n    \n    {\\displaystyle \\mu _{G}}\n  , the optimal discriminator keeps track of the likelihood ratio between the reference distribution and the generator distribution:where \n  \n    \n      \n        σ\n      \n    \n    {\\displaystyle \\sigma }\n   is the logistic function.\nIn particular, if the prior probability for an image \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n   to come from the reference distribution is equal to \n  \n    \n      \n        \n          \n            1\n            2\n          \n        \n      \n    \n    {\\displaystyle {\\frac {1}{2}}}\n  , then \n  \n    \n      \n        D\n        (\n        x\n        )\n      \n    \n    {\\displaystyle D(x)}\n   is just the posterior probability that \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n   came from the reference distribution:","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":767,"to":831}}}}],["4dfc9577-f20e-4084-b7c2-4a1dd7ee1e05",{"pageContent":"== Training and evaluating GAN ==\n\n\n=== Training ===","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":834,"to":837}}}}],["f2d56c05-3cf6-4d5a-9112-a42e95eee3f1",{"pageContent":"==== Unstable convergence ====\nWhile the GAN game has a unique global equilibrium point when both the generator and discriminator have access to their entire strategy sets, the equilibrium is no longer guaranteed when they have a restricted strategy set.In practice, the generator has access only to measures of form \n  \n    \n      \n        \n          μ\n          \n            Z\n          \n        \n        ∘\n        \n          G\n          \n            θ\n          \n          \n            −\n            1\n          \n        \n      \n    \n    {\\displaystyle \\mu _{Z}\\circ G_{\\theta }^{-1}}\n  , where \n  \n    \n      \n        \n          G\n          \n            θ\n          \n        \n      \n    \n    {\\displaystyle G_{\\theta }}\n   is a function computed by a neural network with parameters \n  \n    \n      \n        θ\n      \n    \n    {\\displaystyle \\theta }\n  , and \n  \n    \n      \n        \n          μ\n          \n            Z\n          \n        \n      \n    \n    {\\displaystyle \\mu _{Z}}","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":840,"to":898}}}}],["5e9da455-e6bf-4bf1-8023-16bb0e2b231d",{"pageContent":"θ\n      \n    \n    {\\displaystyle \\theta }\n  , and \n  \n    \n      \n        \n          μ\n          \n            Z\n          \n        \n      \n    \n    {\\displaystyle \\mu _{Z}}\n   is an easily sampled distribution, such as the uniform or normal distribution. Similarly, the discriminator has access only to functions of form \n  \n    \n      \n        \n          D\n          \n            ζ\n          \n        \n      \n    \n    {\\displaystyle D_{\\zeta }}\n  , a function computed by a neural network with parameters \n  \n    \n      \n        ζ\n      \n    \n    {\\displaystyle \\zeta }","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":898,"to":935}}}}],["4fbe0546-f361-4c02-a5d8-67d520afc25c",{"pageContent":"ζ\n          \n        \n      \n    \n    {\\displaystyle D_{\\zeta }}\n  , a function computed by a neural network with parameters \n  \n    \n      \n        ζ\n      \n    \n    {\\displaystyle \\zeta }\n  . These restricted strategy sets take up a vanishingly small proportion of their entire strategy sets.Further, even if an equilibrium still exists, it can only be found by searching in the high-dimensional space of all possible neural network functions. The standard strategy of using gradient descent to find the equilibrium often does not work for GAN, and often the game \"collapses\" into one of several failure modes. To improve the convergence stability, some training strategies start with an easier task, such as generating low-resolution images or simple images (one object with uniform background), and gradually increase the difficulty of the task during training. This essentially translates to applying a curriculum learning scheme.","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":935,"to":949}}}}],["7581a925-65ae-46c8-b734-61e485c29be9",{"pageContent":"==== Mode collapse ====\nGANs often suffer from mode collapse where they fail to generalize properly, missing entire modes from the input data. For example, a GAN trained on the MNIST dataset containing many samples of each digit might only generate pictures of digit 0. This was named in the first paper as the \"Helvetica scenario\".\nOne way this can happen is if the generator learns too fast compared to the discriminator. If the discriminator \n  \n    \n      \n        D\n      \n    \n    {\\displaystyle D}\n   is held constant, then the optimal generator would only output elements of \n  \n    \n      \n        arg\n        ⁡\n        \n          max\n          \n            x\n          \n        \n        D\n        (\n        x\n        )\n      \n    \n    {\\displaystyle \\arg \\max _{x}D(x)}","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":952,"to":980}}}}],["90fb1ffd-5750-43ec-9b49-f39e0fdf27f3",{"pageContent":"arg\n        ⁡\n        \n          max\n          \n            x\n          \n        \n        D\n        (\n        x\n        )\n      \n    \n    {\\displaystyle \\arg \\max _{x}D(x)}\n  . So for example, if during GAN training for generating MNIST dataset, for a few epochs, the discriminator somehow prefers the digit 0 slightly more than other digits, the generator may seize the opportunity to generate only digit 0, then be unable to escape the local minimum after the discriminator improves.\nSome researchers perceive the root problem to be a weak discriminative network that fails to notice the pattern of omission, while others assign blame to a bad choice of objective function. Many solutions have been proposed, but it is still an open problem.Even the state-of-the-art architecture, BigGAN (2019), could not avoid mode collapse. The authors resorted to \"allowing collapse to occur at the later stages of training, by which time a model is sufficiently trained to achieve good results\".","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":980,"to":996}}}}],["f1dc7eec-6df7-4d90-9c14-65e33c6f43be",{"pageContent":"==== Two time-scale update rule ====\nThe two time-scale update rule (TTUR) is proposed to make GAN convergence more stable by making the learning rate of the generator lower than that of the discriminator. The authors argued that the generator should move slower than the discriminator, so that it does not \"drive the discriminator steadily into new regions without capturing its gathered information\".\nThey proved that a general class of games that included the GAN game, when trained under TTUR, \"converges under mild assumptions to a stationary local Nash equilibrium\".They also proposed using the Adam stochastic optimization to avoid mode collapse, as well as the Fréchet inception distance for evaluating GAN performances.","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":999,"to":1001}}}}],["d31f6f76-9e2b-466d-8a0e-656cab4378a9",{"pageContent":"==== Vanishing gradient ====\nConversely, if the discriminator learns too fast compared to the generator, then the discriminator could almost perfectly distinguish \n  \n    \n      \n        \n          μ\n          \n            \n              G\n              \n                θ\n              \n            \n          \n        \n        ,\n        \n          μ\n          \n            r\n            e\n            f\n          \n        \n      \n    \n    {\\displaystyle \\mu _{G_{\\theta }},\\mu _{ref}}\n  . In such case, the generator \n  \n    \n      \n        \n          G\n          \n            θ\n          \n        \n      \n    \n    {\\displaystyle G_{\\theta }}\n   could be stuck with a very high loss no matter which direction it changes its \n  \n    \n      \n        θ\n      \n    \n    {\\displaystyle \\theta }\n  , meaning that the gradient \n  \n    \n      \n        \n          ∇\n          \n            θ\n          \n        \n        L\n        (\n        \n          G\n          \n            θ\n          \n        \n        ,\n        \n          D\n          \n            ζ","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":1004,"to":1075}}}}],["7d412bed-b6ab-411f-afff-bcd24410f17b",{"pageContent":"∇\n          \n            θ\n          \n        \n        L\n        (\n        \n          G\n          \n            θ\n          \n        \n        ,\n        \n          D\n          \n            ζ\n          \n        \n        )\n      \n    \n    {\\displaystyle \\nabla _{\\theta }L(G_{\\theta },D_{\\zeta })}\n   would be close to zero. In such case, the generator cannot learn, a case of the vanishing gradient problem.Intuitively speaking, the discriminator is too good, and since the generator cannot take any small step (only small steps are considered in gradient descent) to improve its payoff, it does not even try.\nOne important method for solving this problem is the Wasserstein GAN.","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":1075,"to":1100}}}}],["51db6166-81a2-4fc1-9711-d968525f6892",{"pageContent":"=== Evaluation ===\nGANs are usually evaluated by Inception score (IS), which measures how varied the generator's outputs are (as classified by an image classifier, usually Inception-v3), or Fréchet inception distance (FID), which measures how similar the generator's outputs are to a reference set (as classified by a learned image featurizer, such as Inception-v3 without its final layer). Many papers that propose new GAN architectures for image generation report how their architectures break the state of the art on FID or IS.\nAnother evaluation method is the Learned Perceptual Image Patch Similarity (LPIPS), which starts with a learned image featurizer \n  \n    \n      \n        \n          f\n          \n            θ\n          \n        \n        :\n        \n          Image\n        \n        →\n        \n          \n            R\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle f_{\\theta }:{\\text{Image}}\\to \\mathbb {R} ^{n}}\n  , and finetunes it by supervised learning on a set of","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":1103,"to":1131}}}}],["d4b59f05-fb09-4d1d-aa7d-3ebde61cae3d",{"pageContent":"n\n          \n        \n      \n    \n    {\\displaystyle f_{\\theta }:{\\text{Image}}\\to \\mathbb {R} ^{n}}\n  , and finetunes it by supervised learning on a set of \n  \n    \n      \n        (\n        x\n        ,\n        \n          x\n          ′\n        \n        ,\n        \n          PerceptualDifference\n        \n        (\n        x\n        ,\n        \n          x\n          ′\n        \n        )\n        )\n      \n    \n    {\\displaystyle (x,x',{\\text{PerceptualDifference}}(x,x'))}\n  , where \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n   is an image, \n  \n    \n      \n        \n          x\n          ′\n        \n      \n    \n    {\\displaystyle x'}\n   is a perturbed version of it, and \n  \n    \n      \n        \n          PerceptualDifference\n        \n        (\n        x\n        ,\n        \n          x\n          ′\n        \n        )\n      \n    \n    {\\displaystyle {\\text{PerceptualDifference}}(x,x')}\n   is how much they differ, as reported by human subjects. The model is finetuned so that it can approximate \n  \n    \n      \n        ‖","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":1131,"to":1205}}}}],["4565dc93-8b71-4ff8-8443-1f9045849128",{"pageContent":"{\\displaystyle {\\text{PerceptualDifference}}(x,x')}\n   is how much they differ, as reported by human subjects. The model is finetuned so that it can approximate \n  \n    \n      \n        ‖\n        \n          f\n          \n            θ\n          \n        \n        (\n        x\n        )\n        −\n        \n          f\n          \n            θ\n          \n        \n        (\n        \n          x\n          ′\n        \n        )\n        ‖\n        ≈\n        \n          PerceptualDifference\n        \n        (\n        x\n        ,\n        \n          x\n          ′\n        \n        )\n      \n    \n    {\\displaystyle \\|f_{\\theta }(x)-f_{\\theta }(x')\\|\\approx {\\text{PerceptualDifference}}(x,x')}\n  . This finetuned model is then used to define \n  \n    \n      \n        \n          LPIPS\n        \n        (\n        x\n        ,\n        \n          x\n          ′\n        \n        )\n        :=\n        ‖\n        \n          f\n          \n            θ\n          \n        \n        (\n        x\n        )\n        −\n        \n          f\n          \n            θ","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":1205,"to":1279}}}}],["987fd1dc-e610-49a6-82ac-1af8502b44db",{"pageContent":")\n        :=\n        ‖\n        \n          f\n          \n            θ\n          \n        \n        (\n        x\n        )\n        −\n        \n          f\n          \n            θ\n          \n        \n        (\n        \n          x\n          ′\n        \n        )\n        ‖\n      \n    \n    {\\displaystyle {\\text{LPIPS}}(x,x'):=\\|f_{\\theta }(x)-f_{\\theta }(x')\\|}\n  .Other evaluation methods are reviewed in.","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":1279,"to":1308}}}}],["b2100385-5297-40c5-8f49-72d80e8033d4",{"pageContent":"== Variants ==\nThere is a veritable zoo of GAN variants. Some of the most prominent are as follows:","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":1311,"to":1312}}}}],["97736f7b-d897-4401-8306-90f6720de07d",{"pageContent":"=== Conditional GAN ===\nConditional GANs are similar to standard GANs except they allow the model to conditionally generate samples based on additional information. For example, if we want to generate a cat face given a dog picture, we could use a conditional GAN\nThe generator in a GAN game generates \n  \n    \n      \n        \n          μ\n          \n            G\n          \n        \n      \n    \n    {\\displaystyle \\mu _{G}}\n  , a probability distribution on the probability space \n  \n    \n      \n        Ω\n      \n    \n    {\\displaystyle \\Omega }\n  . This leads to the idea of a conditional GAN, where instead of generating one probability distribution on \n  \n    \n      \n        Ω\n      \n    \n    {\\displaystyle \\Omega }\n  , the generator generates a different probability distribution \n  \n    \n      \n        \n          μ\n          \n            G\n          \n        \n        (\n        c\n        )\n      \n    \n    {\\displaystyle \\mu _{G}(c)}\n   on \n  \n    \n      \n        Ω\n      \n    \n    {\\displaystyle \\Omega }\n  , for each given class label","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":1315,"to":1370}}}}],["d1f3861a-6965-4b51-81df-1e5eb2097fb4",{"pageContent":"G\n          \n        \n        (\n        c\n        )\n      \n    \n    {\\displaystyle \\mu _{G}(c)}\n   on \n  \n    \n      \n        Ω\n      \n    \n    {\\displaystyle \\Omega }\n  , for each given class label \n  \n    \n      \n        c\n      \n    \n    {\\displaystyle c}\n  .\nFor example, for generating images that look like ImageNet, the generator should be able to generate a picture of cat when given the class label \"cat\".\nIn the original paper, the authors noted that GAN can be trivially extended to conditional GAN by providing the labels to both the generator and the discriminator.\nConcretely, the conditional GAN game is just the GAN game with class labels provided:where \n  \n    \n      \n        \n          μ\n          \n            C\n          \n        \n      \n    \n    {\\displaystyle \\mu _{C}}\n   is a probability distribution over classes, \n  \n    \n      \n        \n          μ\n          \n            r\n            e\n            f\n          \n        \n        (\n        c\n        )\n      \n    \n    {\\displaystyle \\mu _{ref}(c)}","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":1370,"to":1428}}}}],["fdffe069-cbb0-444c-876c-b189c9e60f98",{"pageContent":"μ\n          \n            r\n            e\n            f\n          \n        \n        (\n        c\n        )\n      \n    \n    {\\displaystyle \\mu _{ref}(c)}\n   is the probability distribution of real images of class \n  \n    \n      \n        c\n      \n    \n    {\\displaystyle c}\n  , and \n  \n    \n      \n        \n          μ\n          \n            G\n          \n        \n        (\n        c\n        )\n      \n    \n    {\\displaystyle \\mu _{G}(c)}\n   the probability distribution of images generated by the generator when given class label \n  \n    \n      \n        c\n      \n    \n    {\\displaystyle c}\n  .\nIn 2017, a conditional GAN learned to generate 1000 image classes of ImageNet.","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":1428,"to":1474}}}}],["240e3454-d170-4d3e-85ad-2fad88bd15f9",{"pageContent":"=== GANs with alternative architectures ===\nThe GAN game is a general framework and can be run with any reasonable parametrization of the generator \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n   and discriminator \n  \n    \n      \n        D\n      \n    \n    {\\displaystyle D}\n  . In the original paper, the authors demonstrated it using multilayer perceptron networks and convolutional neural networks. Many alternative architectures have been tried.\nDeep convolutional GAN (DCGAN): For both generator and discriminator, uses only deep networks consisting entirely of convolution-deconvolution layers, that is, fully convolutional networks.Self-attention GAN (SAGAN): Starts with the DCGAN, then adds residually-connected standard self-attention modules to the generator and discriminator.\nVariational autoencoder GAN (VAEGAN): Uses a variational autoencoder (VAE) for the generator.","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":1477,"to":1496}}}}],["511ce78e-24ab-420e-8154-f9e6e0a6e77d",{"pageContent":"Variational autoencoder GAN (VAEGAN): Uses a variational autoencoder (VAE) for the generator.\nTransformer GAN (TransGAN): Uses the pure transformer architecture for both the generator and discriminator, entirely devoid of convolution-deconvolution layers.\nFlow-GAN: Uses flow-based generative model for the generator, allowing efficient computation of the likelihood function.","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":1496,"to":1498}}}}],["124b4349-3d6f-473c-83d3-08aa4491005f",{"pageContent":"=== GANs with alternative objectives ===\nMany GAN variants are merely obtained by changing the loss functions for the generator and discriminator.\nOriginal GAN:\nWe recast the original GAN objective into a form more convenient for comparison:\nOriginal GAN, non-saturating loss:\nThis objective for generator was recommended in the original paper for faster convergence.The effect of using this objective is analyzed in Section 2.2.2 of Arjovsky et al.Original GAN, maximum likelihood:\nwhere \n  \n    \n      \n        σ\n      \n    \n    {\\displaystyle \\sigma }\n   is the logistic function. When the discriminator is optimal, the generator gradient is the same as in maximum likelihood estimation, even though GAN cannot perform maximum likelihood estimation itself.Hinge loss GAN:Least squares GAN:where \n  \n    \n      \n        a\n        ,\n        b\n        ,\n        c\n      \n    \n    {\\displaystyle a,b,c}\n   are parameters to be chosen. The authors recommended \n  \n    \n      \n        a\n        =\n        −\n        1\n        ,\n        b","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":1501,"to":1536}}}}],["77de065d-fd9e-4d16-9191-4e559729c470",{"pageContent":",\n        b\n        ,\n        c\n      \n    \n    {\\displaystyle a,b,c}\n   are parameters to be chosen. The authors recommended \n  \n    \n      \n        a\n        =\n        −\n        1\n        ,\n        b\n        =\n        1\n        ,\n        c\n        =\n        0\n      \n    \n    {\\displaystyle a=-1,b=1,c=0}\n  .","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":1536,"to":1562}}}}],["8cf1f948-dcc4-408c-9525-a24e6a80657c",{"pageContent":"=== Wasserstein GAN (WGAN) ===\n\nThe Wasserstein GAN modifies the GAN game at two points:\n\nThe discriminator's strategy set is the set of measurable functions of type \n  \n    \n      \n        D\n        :\n        Ω\n        →\n        \n          R\n        \n      \n    \n    {\\displaystyle D:\\Omega \\to \\mathbb {R} }\n   with bounded Lipschitz norm: \n  \n    \n      \n        ‖\n        D\n        \n          ‖\n          \n            L\n          \n        \n        ≤\n        K\n      \n    \n    {\\displaystyle \\|D\\|_{L}\\leq K}\n  , where \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n   is a fixed positive constant.\nThe objective isOne of its purposes is to solve the problem of mode collapse (see above). The authors claim \"In no experiment did we see evidence of mode collapse for the WGAN algorithm\".\n\n\n=== GANs with more than 2 players ===","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":1565,"to":1612}}}}],["6c941b70-fede-4f78-9a5a-45ffe67de90a",{"pageContent":"=== GANs with more than 2 players ===\n\n\n==== Adversarial autoencoder ====\nAn adversarial autoencoder (AAE) is more autoencoder than GAN. The idea is to start with a plain autoencoder, but train a discriminator to discriminate the latent vectors from a reference distribution (often the normal distribution).","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":1612,"to":1616}}}}],["2c3c9098-7d1a-4254-995c-2d4aac177b79",{"pageContent":"==== InfoGAN ====\nIn conditional GAN, the generator receives both a noise vector \n  \n    \n      \n        z\n      \n    \n    {\\displaystyle z}\n   and a label \n  \n    \n      \n        c\n      \n    \n    {\\displaystyle c}\n  , and produces an image \n  \n    \n      \n        G\n        (\n        z\n        ,\n        c\n        )\n      \n    \n    {\\displaystyle G(z,c)}\n  . The discriminator receives image-label pairs \n  \n    \n      \n        (\n        x\n        ,\n        c\n        )\n      \n    \n    {\\displaystyle (x,c)}\n  , and computes \n  \n    \n      \n        D\n        (\n        x\n        ,\n        c\n        )\n      \n    \n    {\\displaystyle D(x,c)}\n  .\nWhen the training dataset is unlabeled, conditional GAN does not work directly.\nThe idea of InfoGAN is to decree that every latent vector in the latent space can be decomposed as \n  \n    \n      \n        (\n        z\n        ,\n        c\n        )\n      \n    \n    {\\displaystyle (z,c)}\n  : an incompressible noise part \n  \n    \n      \n        z\n      \n    \n    {\\displaystyle z}\n  , and an informative label part","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":1619,"to":1696}}}}],["22b5baa6-e460-4f81-b496-0ebe45bb52ac",{"pageContent":",\n        c\n        )\n      \n    \n    {\\displaystyle (z,c)}\n  : an incompressible noise part \n  \n    \n      \n        z\n      \n    \n    {\\displaystyle z}\n  , and an informative label part \n  \n    \n      \n        c\n      \n    \n    {\\displaystyle c}\n  , and encourage the generator to comply with the decree, by encouraging it to maximize \n  \n    \n      \n        I\n        (\n        c\n        ,\n        G\n        (\n        z\n        ,\n        c\n        )\n        )\n      \n    \n    {\\displaystyle I(c,G(z,c))}\n  , the mutual information between \n  \n    \n      \n        c\n      \n    \n    {\\displaystyle c}\n   and \n  \n    \n      \n        G\n        (\n        z\n        ,\n        c\n        )\n      \n    \n    {\\displaystyle G(z,c)}\n  , while making no demands on the mutual information \n  \n    \n      \n        z\n      \n    \n    {\\displaystyle z}\n   between \n  \n    \n      \n        G\n        (\n        z\n        ,\n        c\n        )\n      \n    \n    {\\displaystyle G(z,c)}\n  .\nUnfortunately, \n  \n    \n      \n        I\n        (\n        c\n        ,\n        G\n        (\n        z\n        ,","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":1696,"to":1790}}}}],["275aaf2d-919d-4dc0-872d-fba9c8f8d040",{"pageContent":"G\n        (\n        z\n        ,\n        c\n        )\n      \n    \n    {\\displaystyle G(z,c)}\n  .\nUnfortunately, \n  \n    \n      \n        I\n        (\n        c\n        ,\n        G\n        (\n        z\n        ,\n        c\n        )\n        )\n      \n    \n    {\\displaystyle I(c,G(z,c))}\n   is intractable in general, The key idea of InfoGAN is Variational Mutual Information Maximization: indirectly maximize it by maximizing a lower boundwhere \n  \n    \n      \n        Q\n      \n    \n    {\\displaystyle Q}\n   ranges over all Markov kernels of type \n  \n    \n      \n        Q\n        :\n        \n          Ω\n          \n            Y\n          \n        \n        →\n        \n          \n            P\n          \n        \n        (\n        \n          Ω\n          \n            C\n          \n        \n        )\n      \n    \n    {\\displaystyle Q:\\Omega _{Y}\\to {\\mathcal {P}}(\\Omega _{C})}\n  .","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":1790,"to":1855}}}}],["b4093a73-aec9-454b-89ed-aa3b17421958",{"pageContent":"The InfoGAN game is defined as follows:Three probability spaces define an InfoGAN game:\n\n  \n    \n      \n        (\n        \n          Ω\n          \n            X\n          \n        \n        ,\n        \n          μ\n          \n            r\n            e\n            f\n          \n        \n        )\n      \n    \n    {\\displaystyle (\\Omega _{X},\\mu _{ref})}\n  , the space of reference images.\n\n  \n    \n      \n        (\n        \n          Ω\n          \n            Z\n          \n        \n        ,\n        \n          μ\n          \n            Z\n          \n        \n        )\n      \n    \n    {\\displaystyle (\\Omega _{Z},\\mu _{Z})}\n  , the fixed random noise generator.","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":1857,"to":1905}}}}],["c125541d-604d-44b3-b7cb-281b284bfd77",{"pageContent":"(\n        \n          Ω\n          \n            C\n          \n        \n        ,\n        \n          μ\n          \n            C\n          \n        \n        )\n      \n    \n    {\\displaystyle (\\Omega _{C},\\mu _{C})}\n  , the fixed random information generator.There are 3 players in 2 teams: generator, Q, and discriminator. The generator and Q are on one team, and the discriminator on the other team.\nThe objective function iswhere \n  \n    \n      \n        \n          L\n          \n            G\n            A\n            N\n          \n        \n        (\n        G\n        ,\n        D\n        )\n        =\n        \n          \n            E\n          \n          \n            x\n            ∼\n            \n              μ\n              \n                r\n                e\n                f\n              \n            \n            ,\n          \n        \n        [\n        ln\n        ⁡\n        D\n        (\n        x\n        )\n        ]\n        +\n        \n          \n            E\n          \n          \n            z\n            ∼\n            \n              μ","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":1910,"to":1982}}}}],["beef4eab-2b06-4342-bfae-d41815682104",{"pageContent":"[\n        ln\n        ⁡\n        D\n        (\n        x\n        )\n        ]\n        +\n        \n          \n            E\n          \n          \n            z\n            ∼\n            \n              μ\n              \n                Z\n              \n            \n          \n        \n        [\n        ln\n        ⁡\n        (\n        1\n        −\n        D\n        (\n        G\n        (\n        z\n        ,\n        c\n        )\n        )\n        )\n        ]\n      \n    \n    {\\displaystyle L_{GAN}(G,D)=\\mathbb {E} _{x\\sim \\mu _{ref},}[\\ln D(x)]+\\mathbb {E} _{z\\sim \\mu _{Z}}[\\ln(1-D(G(z,c)))]}\n   is the original GAN game objective, and \n  \n    \n      \n        \n          \n            \n              I\n              ^\n            \n          \n        \n        (\n        G\n        ,\n        Q\n        )\n        =\n        \n          \n            E\n          \n          \n            z\n            ∼\n            \n              μ\n              \n                Z\n              \n            \n            ,\n            c\n            ∼\n            \n              μ","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":1982,"to":2061}}}}],["67d8e333-8f90-4189-9998-4549cba584a9",{"pageContent":"z\n            ∼\n            \n              μ\n              \n                Z\n              \n            \n            ,\n            c\n            ∼\n            \n              μ\n              \n                C\n              \n            \n          \n        \n        [\n        ln\n        ⁡\n        Q\n        (\n        c\n        \n          |\n        \n        G\n        (\n        z\n        ,\n        c\n        )\n        )\n        ]\n      \n    \n    {\\displaystyle {\\hat {I}}(G,Q)=\\mathbb {E} _{z\\sim \\mu _{Z},c\\sim \\mu _{C}}[\\ln Q(c|G(z,c))]}","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":2061,"to":2099}}}}],["a24759ba-bc1d-4fa3-bbfc-85f318cf1dc4",{"pageContent":"Generator-Q team aims to minimize the objective, and discriminator aims to maximize it:","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":2102,"to":2102}}}}],["d6c693f7-e022-4d8d-9ee8-61d92df469c0",{"pageContent":"==== Bidirectional GAN (BiGAN) ====\nThe standard GAN generator is a function of type \n  \n    \n      \n        G\n        :\n        \n          Ω\n          \n            Z\n          \n        \n        →\n        \n          Ω\n          \n            X\n          \n        \n      \n    \n    {\\displaystyle G:\\Omega _{Z}\\to \\Omega _{X}}\n  , that is, it is a mapping from a latent space \n  \n    \n      \n        \n          Ω\n          \n            Z\n          \n        \n      \n    \n    {\\displaystyle \\Omega _{Z}}\n   to the image space \n  \n    \n      \n        \n          Ω\n          \n            X\n          \n        \n      \n    \n    {\\displaystyle \\Omega _{X}}\n  . This can be understood as a \"decoding\" process, whereby every latent vector \n  \n    \n      \n        z\n        ∈\n        \n          Ω\n          \n            Z\n          \n        \n      \n    \n    {\\displaystyle z\\in \\Omega _{Z}}\n   is a code for an image \n  \n    \n      \n        x\n        ∈\n        \n          Ω\n          \n            X\n          \n        \n      \n    \n    {\\displaystyle x\\in \\Omega _{X}}","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":2105,"to":2183}}}}],["32480df5-bbb6-4a4f-abf8-5beaf03b16d1",{"pageContent":"{\\displaystyle z\\in \\Omega _{Z}}\n   is a code for an image \n  \n    \n      \n        x\n        ∈\n        \n          Ω\n          \n            X\n          \n        \n      \n    \n    {\\displaystyle x\\in \\Omega _{X}}\n  , and the generator performs the decoding. This naturally leads to the idea of training another network that performs \"encoding\", creating an autoencoder out of the encoder-generator pair.\nAlready in the original paper, the authors noted that \"Learned approximate inference can be performed by training an auxiliary network to predict \n  \n    \n      \n        z\n      \n    \n    {\\displaystyle z}\n   given \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \". The bidirectional GAN architecture performs exactly this.\nThe BiGAN is defined as follows: Two probability spaces define a BiGAN game:","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":2183,"to":2217}}}}],["283df040-3d7e-4388-8cde-7452cd10e1cf",{"pageContent":"(\n        \n          Ω\n          \n            X\n          \n        \n        ,\n        \n          μ\n          \n            X\n          \n        \n        )\n      \n    \n    {\\displaystyle (\\Omega _{X},\\mu _{X})}\n  , the space of reference images.","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":2222,"to":2240}}}}],["920b767a-6f41-4987-b344-c133d50a38a3",{"pageContent":"(\n        \n          Ω\n          \n            Z\n          \n        \n        ,\n        \n          μ\n          \n            Z\n          \n        \n        )\n      \n    \n    {\\displaystyle (\\Omega _{Z},\\mu _{Z})}\n  , the latent space.There are 3 players in 2 teams: generator, encoder, and discriminator. The generator and encoder are on one team, and the discriminator on the other team.\nThe generator's strategies are functions \n  \n    \n      \n        G\n        :\n        \n          Ω\n          \n            Z\n          \n        \n        →\n        \n          Ω\n          \n            X\n          \n        \n      \n    \n    {\\displaystyle G:\\Omega _{Z}\\to \\Omega _{X}}\n  , and the encoder's strategies are functions \n  \n    \n      \n        E\n        :\n        \n          Ω\n          \n            X\n          \n        \n        →\n        \n          Ω\n          \n            Z\n          \n        \n      \n    \n    {\\displaystyle E:\\Omega _{X}\\to \\Omega _{Z}}\n  . The discriminator's strategies are functions \n  \n    \n      \n        D\n        :","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":2245,"to":2313}}}}],["68d300b7-9cb6-4d08-93e5-d46d2170d770",{"pageContent":"Ω\n          \n            Z\n          \n        \n      \n    \n    {\\displaystyle E:\\Omega _{X}\\to \\Omega _{Z}}\n  . The discriminator's strategies are functions \n  \n    \n      \n        D\n        :\n        \n          Ω\n          \n            X\n          \n        \n        →\n        [\n        0\n        ,\n        1\n        ]\n      \n    \n    {\\displaystyle D:\\Omega _{X}\\to [0,1]}\n  .\nThe objective function is","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":2313,"to":2343}}}}],["12446534-af55-4af5-b2df-ef67c96d472e",{"pageContent":"Generator-encoder team aims to minimize the objective, and discriminator aims to maximize it: In the paper, they gave a more abstract definition of the objective as:where \n  \n    \n      \n        \n          μ\n          \n            E\n            ,\n            X\n          \n        \n        (\n        d\n        x\n        ,\n        d\n        z\n        )\n        =\n        \n          μ\n          \n            X\n          \n        \n        (\n        d\n        x\n        )\n        ⋅\n        \n          δ\n          \n            E\n            (\n            x\n            )\n          \n        \n        (\n        d\n        z\n        )\n      \n    \n    {\\displaystyle \\mu _{E,X}(dx,dz)=\\mu _{X}(dx)\\cdot \\delta _{E(x)}(dz)}\n   is the probability distribution on \n  \n    \n      \n        \n          Ω\n          \n            X\n          \n        \n        ×\n        \n          Ω\n          \n            Z\n          \n        \n      \n    \n    {\\displaystyle \\Omega _{X}\\times \\Omega _{Z}}\n   obtained by pushing \n  \n    \n      \n        \n          μ\n          \n            X","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":2345,"to":2419}}}}],["9cc885b6-b74a-4b87-911d-eb6b2ff31b12",{"pageContent":"Z\n          \n        \n      \n    \n    {\\displaystyle \\Omega _{X}\\times \\Omega _{Z}}\n   obtained by pushing \n  \n    \n      \n        \n          μ\n          \n            X\n          \n        \n      \n    \n    {\\displaystyle \\mu _{X}}\n   forward via \n  \n    \n      \n        x\n        ↦\n        (\n        x\n        ,\n        E\n        (\n        x\n        )\n        )\n      \n    \n    {\\displaystyle x\\mapsto (x,E(x))}\n  , and \n  \n    \n      \n        \n          μ\n          \n            G\n            ,\n            Z\n          \n        \n        (\n        d\n        x\n        ,\n        d\n        z\n        )\n        =\n        \n          δ\n          \n            G\n            (\n            z\n            )\n          \n        \n        (\n        d\n        x\n        )\n        ⋅\n        \n          μ\n          \n            Z\n          \n        \n        (\n        d\n        z\n        )\n      \n    \n    {\\displaystyle \\mu _{G,Z}(dx,dz)=\\delta _{G(z)}(dx)\\cdot \\mu _{Z}(dz)}\n   is the probability distribution on \n  \n    \n      \n        \n          Ω\n          \n            X","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":2419,"to":2509}}}}],["ac9ee6c1-6bf3-4fd9-af5b-b774a41aef73",{"pageContent":"z\n        )\n      \n    \n    {\\displaystyle \\mu _{G,Z}(dx,dz)=\\delta _{G(z)}(dx)\\cdot \\mu _{Z}(dz)}\n   is the probability distribution on \n  \n    \n      \n        \n          Ω\n          \n            X\n          \n        \n        ×\n        \n          Ω\n          \n            Z\n          \n        \n      \n    \n    {\\displaystyle \\Omega _{X}\\times \\Omega _{Z}}\n   obtained by pushing \n  \n    \n      \n        \n          μ\n          \n            Z\n          \n        \n      \n    \n    {\\displaystyle \\mu _{Z}}\n   forward via \n  \n    \n      \n        z\n        ↦\n        (\n        G\n        (\n        x\n        )\n        ,\n        z\n        )\n      \n    \n    {\\displaystyle z\\mapsto (G(x),z)}\n  .\nApplications of bidirectional models include semi-supervised learning, interpretable machine learning, and neural machine translation.","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":2509,"to":2565}}}}],["c17fef1f-8cae-4dbd-b6c9-6978a6d2b6b1",{"pageContent":"==== CycleGAN ====\nCycleGAN is an architecture for performing translations between two domains, such as between photos of horses and photos of zebras, or photos of night cities and photos of day cities.","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":2568,"to":2569}}}}],["54c1e592-8d0a-474b-9170-eee3beed4b45",{"pageContent":"The CycleGAN game is defined as follows:There are two probability spaces \n  \n    \n      \n        (\n        \n          Ω\n          \n            X\n          \n        \n        ,\n        \n          μ\n          \n            X\n          \n        \n        )\n        ,\n        (\n        \n          Ω\n          \n            Y\n          \n        \n        ,\n        \n          μ\n          \n            Y\n          \n        \n        )\n      \n    \n    {\\displaystyle (\\Omega _{X},\\mu _{X}),(\\Omega _{Y},\\mu _{Y})}\n  , corresponding to the two domains needed for translations fore-and-back.\nThere are 4 players in 2 teams: generators \n  \n    \n      \n        \n          G\n          \n            X\n          \n        \n        :\n        \n          Ω\n          \n            X\n          \n        \n        →\n        \n          Ω\n          \n            Y\n          \n        \n        ,\n        \n          G\n          \n            Y\n          \n        \n        :\n        \n          Ω\n          \n            Y\n          \n        \n        →\n        \n          Ω\n          \n            X","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":2571,"to":2652}}}}],["f8106908-880d-42d0-8df6-ac3eaa05393d",{"pageContent":"G\n          \n            Y\n          \n        \n        :\n        \n          Ω\n          \n            Y\n          \n        \n        →\n        \n          Ω\n          \n            X\n          \n        \n      \n    \n    {\\displaystyle G_{X}:\\Omega _{X}\\to \\Omega _{Y},G_{Y}:\\Omega _{Y}\\to \\Omega _{X}}\n  , and discriminators \n  \n    \n      \n        \n          D\n          \n            X\n          \n        \n        :\n        \n          Ω\n          \n            X\n          \n        \n        →\n        [\n        0\n        ,\n        1\n        ]\n        ,\n        \n          D\n          \n            Y\n          \n        \n        :\n        \n          Ω\n          \n            Y\n          \n        \n        →\n        [\n        0\n        ,\n        1\n        ]\n      \n    \n    {\\displaystyle D_{X}:\\Omega _{X}\\to [0,1],D_{Y}:\\Omega _{Y}\\to [0,1]}\n  .\nThe objective function is","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":2652,"to":2721}}}}],["350a59ce-987e-4b9b-a450-e9be0679e6c9",{"pageContent":"where \n  \n    \n      \n        λ\n      \n    \n    {\\displaystyle \\lambda }\n   is a positive adjustable parameter, \n  \n    \n      \n        \n          L\n          \n            G\n            A\n            N\n          \n        \n      \n    \n    {\\displaystyle L_{GAN}}\n   is the GAN game objective, and \n  \n    \n      \n        \n          L\n          \n            c\n            y\n            c\n            l\n            e\n          \n        \n      \n    \n    {\\displaystyle L_{cycle}}\n   is the cycle consistency loss:The generators aim to minimize the objective, and the discriminators aim to maximize it:  Unlike previous work like pix2pix, which requires paired training data, cycleGAN requires no paired data. For example, to train a pix2pix model to turn a summer scenery photo to winter scenery photo and back, the dataset must contain pairs of the same place in summer and winter, shot at the same angle; cycleGAN would only need a set of summer scenery photos, and an unrelated set of winter scenery photos.","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":2723,"to":2763}}}}],["4515d2e3-8059-403d-8467-f7c470fd0d6f",{"pageContent":"=== GANs with particularly large or small scales ===\n\n\n==== BigGAN ====\nThe BigGAN is essentially a self-attention GAN trained on a large scale (up to 80 million parameters) to generate large images of ImageNet (up to 512 x 512 resolution), with numerous engineering tricks to make it converge.","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":2766,"to":2770}}}}],["6e63e013-a01b-4063-bc8a-604a4a963cc2",{"pageContent":"==== Invertible data augmentation ====\nWhen there is insufficient training data, the reference distribution \n  \n    \n      \n        \n          μ\n          \n            r\n            e\n            f\n          \n        \n      \n    \n    {\\displaystyle \\mu _{ref}}\n   cannot be well-approximated by the empirical distribution given by the training dataset. In such cases, data augmentation can be applied, to allow training GAN on smaller datasets. Naïve data augmentation, however, brings its problems.\nConsider the original GAN game, slightly reformulated as follows:Now we use data augmentation by randomly sampling semantic-preserving transforms \n  \n    \n      \n        T\n        :\n        Ω\n        →\n        Ω\n      \n    \n    {\\displaystyle T:\\Omega \\to \\Omega }\n   and applying them to the dataset, to obtain the reformulated GAN game:This is equivalent to a GAN game with a different distribution \n  \n    \n      \n        \n          μ\n          \n            r\n            e\n            f\n          \n          ′","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":2773,"to":2813}}}}],["0d80b4b9-6d25-418e-87d1-e017fa30a622",{"pageContent":"μ\n          \n            r\n            e\n            f\n          \n          ′\n        \n      \n    \n    {\\displaystyle \\mu _{ref}'}\n  , sampled by \n  \n    \n      \n        T\n        (\n        x\n        )\n      \n    \n    {\\displaystyle T(x)}\n  , with \n  \n    \n      \n        x\n        ∼\n        \n          μ\n          \n            r\n            e\n            f\n          \n        \n        ,\n        T\n        ∼\n        \n          μ\n          \n            t\n            r\n            a\n            n\n            s\n          \n        \n      \n    \n    {\\displaystyle x\\sim \\mu _{ref},T\\sim \\mu _{trans}}\n  . For example, if \n  \n    \n      \n        \n          μ\n          \n            r\n            e\n            f\n          \n        \n      \n    \n    {\\displaystyle \\mu _{ref}}\n   is the distribution of images in ImageNet, and \n  \n    \n      \n        \n          μ\n          \n            t\n            r\n            a\n            n\n            s\n          \n        \n      \n    \n    {\\displaystyle \\mu _{trans}}","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":2813,"to":2896}}}}],["62f2cdec-8ee5-468a-abcb-e763f7b3a1aa",{"pageContent":"μ\n          \n            t\n            r\n            a\n            n\n            s\n          \n        \n      \n    \n    {\\displaystyle \\mu _{trans}}\n   samples identity-transform with probability 0.5, and horizontal-reflection with probability 0.5, then \n  \n    \n      \n        \n          μ\n          \n            r\n            e\n            f\n          \n          ′\n        \n      \n    \n    {\\displaystyle \\mu _{ref}'}\n   is the distribution of images in ImageNet and horizontally-reflected ImageNet, combined.\nThe result of such training would be a generator that mimics \n  \n    \n      \n        \n          μ\n          \n            r\n            e\n            f\n          \n          ′\n        \n      \n    \n    {\\displaystyle \\mu _{ref}'}\n  . For example, it would generate images that look like they are randomly cropped, if the data augmentation uses random cropping.","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":2896,"to":2941}}}}],["e8cc3e5a-bd7e-4fe6-a4a6-3ae1177e6266",{"pageContent":"′\n        \n      \n    \n    {\\displaystyle \\mu _{ref}'}\n  . For example, it would generate images that look like they are randomly cropped, if the data augmentation uses random cropping.\nThe solution is to apply data augmentation to both generated and real images:The authors demonstrated high-quality generation using just 100-picture-large datasets.The StyleGAN-2-ADA paper points out a further point on data augmentation: it must be invertible. Continue with the example of generating ImageNet pictures. If the data augmentation is \"randomly rotate the picture by 0, 90, 180, 270 degrees with equal probability\", then there is no way for the generator to know which is the true orientation: Consider two generators \n  \n    \n      \n        G\n        ,\n        \n          G\n          ′\n        \n      \n    \n    {\\displaystyle G,G'}\n  , such that for any latent \n  \n    \n      \n        z\n      \n    \n    {\\displaystyle z}\n  , the generated image \n  \n    \n      \n        G\n        (\n        z\n        )","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":2941,"to":2975}}}}],["ae69eda5-eda2-4f36-a354-7ef1d93c14e2",{"pageContent":"{\\displaystyle G,G'}\n  , such that for any latent \n  \n    \n      \n        z\n      \n    \n    {\\displaystyle z}\n  , the generated image \n  \n    \n      \n        G\n        (\n        z\n        )\n      \n    \n    {\\displaystyle G(z)}\n   is a 90-degree rotation of \n  \n    \n      \n        \n          G\n          ′\n        \n        (\n        z\n        )\n      \n    \n    {\\displaystyle G'(z)}\n  . They would have exactly the same expected loss, and so neither is preferred over the other.\nThe solution is to only use invertible data augmentation: instead of \"randomly rotate the picture by 0, 90, 180, 270 degrees with equal probability\", use \"randomly rotate the picture by 90, 180, 270 degrees with 0.1 probability, and keep the picture as it is with 0.7 probability\". This way, the generator is still rewarded  to keep images oriented the same way as un-augmented ImageNet pictures.\nAbstractly, the effect of randomly sampling transformations \n  \n    \n      \n        T\n        :\n        Ω\n        →\n        Ω","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":2975,"to":3019}}}}],["f5293f10-eb3f-42d5-ae5c-1a037a6ec896",{"pageContent":"Abstractly, the effect of randomly sampling transformations \n  \n    \n      \n        T\n        :\n        Ω\n        →\n        Ω\n      \n    \n    {\\displaystyle T:\\Omega \\to \\Omega }\n   from the distribution \n  \n    \n      \n        \n          μ\n          \n            t\n            r\n            a\n            n\n            s\n          \n        \n      \n    \n    {\\displaystyle \\mu _{trans}}\n   is to define a Markov kernel \n  \n    \n      \n        \n          K\n          \n            t\n            r\n            a\n            n\n            s\n          \n        \n        :\n        Ω\n        →\n        \n          \n            P\n          \n        \n        (\n        Ω\n        )\n      \n    \n    {\\displaystyle K_{trans}:\\Omega \\to {\\mathcal {P}}(\\Omega )}\n  . Then, the data-augmented GAN game pushes the generator to find some \n  \n    \n      \n        \n          \n            \n              \n                μ\n                ^\n              \n            \n          \n          \n            G\n          \n        \n        ∈\n        \n          \n            P\n          \n        \n        (","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":3019,"to":3099}}}}],["62a77461-9847-4cb4-86bf-4c0d6b651cee",{"pageContent":"μ\n                ^\n              \n            \n          \n          \n            G\n          \n        \n        ∈\n        \n          \n            P\n          \n        \n        (\n        Ω\n        )\n      \n    \n    {\\displaystyle {\\hat {\\mu }}_{G}\\in {\\mathcal {P}}(\\Omega )}\n  , such that where \n  \n    \n      \n        ∗\n      \n    \n    {\\displaystyle *}\n   is the Markov kernel convolution.\nA data-augmentation method is defined to be invertible if its Markov kernel \n  \n    \n      \n        \n          K\n          \n            t\n            r\n            a\n            n\n            s\n          \n        \n      \n    \n    {\\displaystyle K_{trans}}\n   satisfiesImmediately by definition, we see that composing multiple invertible data-augmentation methods results in yet another invertible method. Also by definition, if the data-augmentation method is invertible, then using it in a GAN game does not change the optimal strategy \n  \n    \n      \n        \n          \n            \n              \n                μ","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":3099,"to":3154}}}}],["e1623328-ad8b-44ef-b3e1-91370db4fee6",{"pageContent":"μ\n                ^\n              \n            \n          \n          \n            G\n          \n        \n      \n    \n    {\\displaystyle {\\hat {\\mu }}_{G}}\n   for the generator, which is still \n  \n    \n      \n        \n          μ\n          \n            r\n            e\n            f\n          \n        \n      \n    \n    {\\displaystyle \\mu _{ref}}\n  .\nThere are two prototypical examples of invertible Markov kernels:\nDiscrete case: Invertible stochastic matrices, when \n  \n    \n      \n        Ω\n      \n    \n    {\\displaystyle \\Omega }\n   is finite.\nFor example, if \n  \n    \n      \n        Ω\n        =\n        {\n        ↑\n        ,\n        ↓\n        ,\n        ←\n        ,\n        →\n        }\n      \n    \n    {\\displaystyle \\Omega =\\{\\uparrow ,\\downarrow ,\\leftarrow ,\\rightarrow \\}}\n   is the set of four images of an arrow, pointing in 4 directions, and the data augmentation is \"randomly rotate the picture by 90, 180, 270 degrees with probability \n  \n    \n      \n        p","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":3154,"to":3214}}}}],["5c51cad3-b62a-445f-9f01-c25c205bc948",{"pageContent":"is the set of four images of an arrow, pointing in 4 directions, and the data augmentation is \"randomly rotate the picture by 90, 180, 270 degrees with probability \n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n  , and keep the picture as it is with probability \n  \n    \n      \n        (\n        1\n        −\n        3\n        p\n        )\n      \n    \n    {\\displaystyle (1-3p)}\n  \", then the Markov kernel \n  \n    \n      \n        \n          K\n          \n            t\n            r\n            a\n            n\n            s\n          \n        \n      \n    \n    {\\displaystyle K_{trans}}\n   can be represented as a stochastic matrix: and \n  \n    \n      \n        \n          K\n          \n            t\n            r\n            a\n            n\n            s\n          \n        \n      \n    \n    {\\displaystyle K_{trans}}\n   is an invertible kernel iff \n  \n    \n      \n        [\n        \n          K\n          \n            t\n            r\n            a\n            n\n            s\n          \n        \n        ]\n      \n    \n    {\\displaystyle [K_{trans}]}","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":3214,"to":3287}}}}],["21bbe001-6d5a-42fd-a36a-89f7c958e942",{"pageContent":"[\n        \n          K\n          \n            t\n            r\n            a\n            n\n            s\n          \n        \n        ]\n      \n    \n    {\\displaystyle [K_{trans}]}\n   is an invertible matrix, that is, \n  \n    \n      \n        p\n        ≠\n        1\n        \n          /\n        \n        4\n      \n    \n    {\\displaystyle p\\neq 1/4}\n  .\nContinuous case: The gaussian kernel, when \n  \n    \n      \n        Ω\n        =\n        \n          \n            R\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\Omega =\\mathbb {R} ^{n}}\n   for some \n  \n    \n      \n        n\n        ≥\n        1\n      \n    \n    {\\displaystyle n\\geq 1}\n  .\nFor example, if \n  \n    \n      \n        Ω\n        =\n        \n          \n            R\n          \n          \n            \n              256\n              \n                2\n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\Omega =\\mathbb {R} ^{256^{2}}}\n   is the space of 256x256 images, and the data-augmentation method is \"generate a gaussian noise","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":3287,"to":3367}}}}],["cd45e0dd-f6de-4802-935d-f8253a8d0294",{"pageContent":"{\\displaystyle \\Omega =\\mathbb {R} ^{256^{2}}}\n   is the space of 256x256 images, and the data-augmentation method is \"generate a gaussian noise \n  \n    \n      \n        z\n        ∼\n        \n          \n            N\n          \n        \n        (\n        0\n        ,\n        \n          I\n          \n            \n              256\n              \n                2\n              \n            \n          \n        \n        )\n      \n    \n    {\\displaystyle z\\sim {\\mathcal {N}}(0,I_{256^{2}})}\n  , then add \n  \n    \n      \n        ϵ\n        z\n      \n    \n    {\\displaystyle \\epsilon z}\n   to the image\", then \n  \n    \n      \n        \n          K\n          \n            t\n            r\n            a\n            n\n            s\n          \n        \n      \n    \n    {\\displaystyle K_{trans}}\n   is just convolution by the density function of \n  \n    \n      \n        \n          \n            N\n          \n        \n        (\n        0\n        ,\n        \n          ϵ\n          \n            2\n          \n        \n        \n          I","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":3367,"to":3442}}}}],["5709dffb-b818-416e-9143-7527093f9370",{"pageContent":"N\n          \n        \n        (\n        0\n        ,\n        \n          ϵ\n          \n            2\n          \n        \n        \n          I\n          \n            \n              256\n              \n                2\n              \n            \n          \n        \n        )\n      \n    \n    {\\displaystyle {\\mathcal {N}}(0,\\epsilon ^{2}I_{256^{2}})}\n  . This is invertible, because convolution by a gaussian is just convolution by the heat kernel, so given any \n  \n    \n      \n        μ\n        ∈\n        \n          \n            P\n          \n        \n        (\n        \n          \n            R\n          \n          \n            n\n          \n        \n        )\n      \n    \n    {\\displaystyle \\mu \\in {\\mathcal {P}}(\\mathbb {R} ^{n})}\n  , the convolved distribution \n  \n    \n      \n        \n          K\n          \n            t\n            r\n            a\n            n\n            s\n          \n        \n        ∗\n        μ\n      \n    \n    {\\displaystyle K_{trans}*\\mu }\n   can be obtained by heating up","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":3442,"to":3512}}}}],["68e27d57-0e6b-4416-b7d3-fd3c2da49b2b",{"pageContent":"t\n            r\n            a\n            n\n            s\n          \n        \n        ∗\n        μ\n      \n    \n    {\\displaystyle K_{trans}*\\mu }\n   can be obtained by heating up \n  \n    \n      \n        \n          \n            R\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {R} ^{n}}\n   precisely according to \n  \n    \n      \n        μ\n      \n    \n    {\\displaystyle \\mu }\n  , then wait for time \n  \n    \n      \n        \n          ϵ\n          \n            2\n          \n        \n        \n          /\n        \n        4\n      \n    \n    {\\displaystyle \\epsilon ^{2}/4}\n  . With that, we can recover \n  \n    \n      \n        μ\n      \n    \n    {\\displaystyle \\mu }\n   by running the heat equation backwards in time for \n  \n    \n      \n        \n          ϵ\n          \n            2\n          \n        \n        \n          /\n        \n        4\n      \n    \n    {\\displaystyle \\epsilon ^{2}/4}\n  .\nMore examples of invertible data augmentations are found in the paper.","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":3512,"to":3590}}}}],["4d78f4b3-ccc3-491e-aeef-28f521fa2165",{"pageContent":"==== SinGAN ====\nSinGAN pushes data augmentation to the limit, by using only a single image as training data and performing data augmentation on it. The GAN architecture is adapted to this training method by using a multi-scale pipeline.\nThe generator \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n   is decomposed into a pyramid of generators \n  \n    \n      \n        G\n        =\n        \n          G\n          \n            1\n          \n        \n        ∘\n        \n          G\n          \n            2\n          \n        \n        ∘\n        ⋯\n        ∘\n        \n          G\n          \n            N\n          \n        \n      \n    \n    {\\displaystyle G=G_{1}\\circ G_{2}\\circ \\cdots \\circ G_{N}}\n  , with the lowest one generating the image \n  \n    \n      \n        \n          G\n          \n            N\n          \n        \n        (\n        \n          z\n          \n            N\n          \n        \n        )\n      \n    \n    {\\displaystyle G_{N}(z_{N})}\n   at the lowest resolution, then the generated image is scaled up to \n  \n    \n      \n        r","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":3593,"to":3659}}}}],["ff95771e-54c4-49ff-9ed6-69920c2a8e2a",{"pageContent":"z\n          \n            N\n          \n        \n        )\n      \n    \n    {\\displaystyle G_{N}(z_{N})}\n   at the lowest resolution, then the generated image is scaled up to \n  \n    \n      \n        r\n        (\n        \n          G\n          \n            N\n          \n        \n        (\n        \n          z\n          \n            N\n          \n        \n        )\n        )\n      \n    \n    {\\displaystyle r(G_{N}(z_{N}))}\n  , and fed to the next level to generate an image \n  \n    \n      \n        \n          G\n          \n            N\n            −\n            1\n          \n        \n        (\n        \n          z\n          \n            N\n            −\n            1\n          \n        \n        +\n        r\n        (\n        \n          G\n          \n            N\n          \n        \n        (\n        \n          z\n          \n            N\n          \n        \n        )\n        )\n        )\n      \n    \n    {\\displaystyle G_{N-1}(z_{N-1}+r(G_{N}(z_{N})))}\n   at a higher resolution, and so on. The discriminator is decomposed into a pyramid as well.","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":3659,"to":3735}}}}],["a865e460-86db-46ac-9d73-75646fa17203",{"pageContent":"=== StyleGAN series ===\n\nThe StyleGAN family is a series of architectures published by Nvidia's research division.","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":3738,"to":3740}}}}],["71250f02-8b8e-4e10-aae0-a41207acf658",{"pageContent":"==== Progressive GAN ====\nProgressive GAN is a method for training GAN for large-scale image generation stably, by growing a GAN generator from small to large scale in a pyramidal fashion. Like SinGAN, it decomposes the generator as\n  \n    \n      \n        G\n        =\n        \n          G\n          \n            1\n          \n        \n        ∘\n        \n          G\n          \n            2\n          \n        \n        ∘\n        ⋯\n        ∘\n        \n          G\n          \n            N\n          \n        \n      \n    \n    {\\displaystyle G=G_{1}\\circ G_{2}\\circ \\cdots \\circ G_{N}}\n  , and the discriminator as \n  \n    \n      \n        D\n        =\n        \n          D\n          \n            1\n          \n        \n        ∘\n        \n          D\n          \n            2\n          \n        \n        ∘\n        ⋯\n        ∘\n        \n          D\n          \n            N\n          \n        \n      \n    \n    {\\displaystyle D=D_{1}\\circ D_{2}\\circ \\cdots \\circ D_{N}}\n  .\nDuring training, at first only \n  \n    \n      \n        \n          G\n          \n            N","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":3743,"to":3814}}}}],["658ed410-8a80-483b-981d-16618ec50cc1",{"pageContent":"{\\displaystyle D=D_{1}\\circ D_{2}\\circ \\cdots \\circ D_{N}}\n  .\nDuring training, at first only \n  \n    \n      \n        \n          G\n          \n            N\n          \n        \n        ,\n        \n          D\n          \n            N\n          \n        \n      \n    \n    {\\displaystyle G_{N},D_{N}}\n   are used in a GAN game to generate 4x4 images. Then \n  \n    \n      \n        \n          G\n          \n            N\n            −\n            1\n          \n        \n        ,\n        \n          D\n          \n            N\n            −\n            1\n          \n        \n      \n    \n    {\\displaystyle G_{N-1},D_{N-1}}\n   are added to reach the second stage of GAN game, to generate 8x8 images, and so on, until we reach a GAN game to generate 1024x1024 images.\nTo avoid shock between stages of the GAN game, each new layer is \"blended in\" (Figure 2 of the paper). For example, this is how the second stage GAN game starts:","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":3814,"to":3861}}}}],["45171cb7-b1c5-4f2e-89fa-1327301c815a",{"pageContent":"Just before, the GAN game consists of the pair \n  \n    \n      \n        \n          G\n          \n            N\n          \n        \n        ,\n        \n          D\n          \n            N\n          \n        \n      \n    \n    {\\displaystyle G_{N},D_{N}}\n   generating and discriminating 4x4 images.\nJust after, the GAN game consists of the pair \n  \n    \n      \n        (\n        (\n        1\n        −\n        α\n        )\n        +\n        α\n        ⋅\n        \n          G\n          \n            N\n            −\n            1\n          \n        \n        )\n        ∘\n        u\n        ∘\n        \n          G\n          \n            N\n          \n        \n        ,\n        \n          D\n          \n            N\n          \n        \n        ∘\n        d\n        ∘\n        (\n        (\n        1\n        −\n        α\n        )\n        +\n        α\n        ⋅\n        \n          D\n          \n            N\n            −\n            1\n          \n        \n        )","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":3863,"to":3942}}}}],["6a1fdd95-0164-45c3-8f6a-468fb9bdeb4e",{"pageContent":"∘\n        (\n        (\n        1\n        −\n        α\n        )\n        +\n        α\n        ⋅\n        \n          D\n          \n            N\n            −\n            1\n          \n        \n        )\n      \n    \n    {\\displaystyle ((1-\\alpha )+\\alpha \\cdot G_{N-1})\\circ u\\circ G_{N},D_{N}\\circ d\\circ ((1-\\alpha )+\\alpha \\cdot D_{N-1})}\n   generating and discriminating 8x8 images. Here, the functions \n  \n    \n      \n        u\n        ,\n        d\n      \n    \n    {\\displaystyle u,d}\n   are image up- and down-sampling functions, and \n  \n    \n      \n        α\n      \n    \n    {\\displaystyle \\alpha }\n   is a blend-in factor (much like an alpha in image composing) that smoothly glides from 0 to 1.","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":3942,"to":3982}}}}],["fd267167-a3cd-4818-a0ac-d59f3f6d6f94",{"pageContent":"==== StyleGAN-1 ====","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":3985,"to":3985}}}}],["8f0e3a75-9b50-465e-a42a-04a337200b74",{"pageContent":"StyleGAN-1 is designed as a combination of Progressive GAN with neural style transfer.The key architectural choice of StyleGAN-1 is a progressive growth mechanism, similar to Progressive GAN. Each generated image starts as a constant \n  \n    \n      \n        4\n        ×\n        4\n        ×\n        512\n      \n    \n    {\\displaystyle 4\\times 4\\times 512}\n   array, and repeatedly passed through style blocks. Each style block applies a \"style latent vector\" via affine transform (\"adaptive instance normalization\"), similar to how neural style transfer uses Gramian matrix. It then adds noise, and normalize (subtract the mean, then divide by the variance).\nAt training time, usually only one style latent vector is used per image generated, but sometimes two (\"mixing regularization\") in order to encourage each style block to independently perform its stylization without expecting help from other style blocks (since they might receive an entirely different style latent vector).","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":3987,"to":4000}}}}],["2614f9ce-f5b6-45a1-b539-106fdb0a0474",{"pageContent":"After training, multiple style latent vectors can be fed into each style block. Those fed to the lower layers control the large-scale styles, and those fed to the higher layers control the fine-detail styles.\nStyle-mixing between two images \n  \n    \n      \n        x\n        ,\n        \n          x\n          ′\n        \n      \n    \n    {\\displaystyle x,x'}\n   can be performed as well. First, run a gradient descent to find \n  \n    \n      \n        z\n        ,\n        \n          z\n          ′\n        \n      \n    \n    {\\displaystyle z,z'}\n   such that \n  \n    \n      \n        G\n        (\n        z\n        )\n        ≈\n        x\n        ,\n        G\n        (\n        \n          z\n          ′\n        \n        )\n        ≈\n        \n          x\n          ′\n        \n      \n    \n    {\\displaystyle G(z)\\approx x,G(z')\\approx x'}\n  . This is called \"projecting an image back to style latent space\". Then, \n  \n    \n      \n        z\n      \n    \n    {\\displaystyle z}\n   can be fed to the lower style blocks, and \n  \n    \n      \n        \n          z\n          ′","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":4001,"to":4068}}}}],["1ac320b7-a833-4124-ba0d-812bae285ad6",{"pageContent":"z\n      \n    \n    {\\displaystyle z}\n   can be fed to the lower style blocks, and \n  \n    \n      \n        \n          z\n          ′\n        \n      \n    \n    {\\displaystyle z'}\n   to the higher style blocks, to generate a composite image that has the large-scale style of \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  , and the fine-detail style of \n  \n    \n      \n        \n          x\n          ′\n        \n      \n    \n    {\\displaystyle x'}\n  . Multiple images can also be composed this way.","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":4068,"to":4102}}}}],["80ca790e-e188-4452-a187-09cc81e152f5",{"pageContent":"==== StyleGAN-2 ====\nStyleGAN-2 improves upon StyleGAN-1, by using the style latent vector to transform the convolution layer's weights instead, thus solving the \"blob\" problem.This was updated by the StyleGAN-2-ADA (\"ADA\" stands for \"adaptive\"), which uses invertible data augmentation as described above. It also tunes the amount of data augmentation applied by starting at zero, and gradually increasing it until an \"overfitting heuristic\" reaches a target level, thus the name \"adaptive\".","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":4105,"to":4106}}}}],["36470f2b-3c1b-4af4-a07e-7459c7d0cd65",{"pageContent":"==== StyleGAN-3 ====\nStyleGAN-3 improves upon StyleGAN-2 by solving the \"texture sticking\" problem, which can be seen in the official videos. They analyzed the problem by the Nyquist–Shannon sampling theorem, and argued that the layers in the generator learned to exploit the high-frequency signal in the pixels they operate upon.\nTo solve this, they proposed imposing strict lowpass filters between each generator's layers, so that the generator is forced to operate on the pixels in a way faithful to the continuous signals they represent, rather than operate on them as merely discrete signals. They further imposed rotational and translational invariance by using more signal filters. The resulting StyleGAN-3 is able to solve the texture sticking problem, as well as generating images that rotate and translate smoothly.\n\n\n== Applications ==\nGAN applications have increased rapidly.\n\n\n=== Fashion, art and advertising ===","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":4109,"to":4118}}}}],["0303f857-6342-40e3-9e81-9b58b91b8151",{"pageContent":"== Applications ==\nGAN applications have increased rapidly.\n\n\n=== Fashion, art and advertising ===\n\nGANs can be used to generate art; The Verge wrote in March 2019 that \"The images created by GANs have become the defining look of contemporary AI art.\" GANs can also be used to inpaint photographs or create photos of imaginary fashion models, with no need to hire a model, photographer or makeup artist, or pay for a studio and transportation. GANs have also been used for virtual shadow generation.\n\n\n=== Interactive Media ===\nIn 2020, Artbreeder was used to create the main antagonist in the sequel to the psychological web horror series Ben Drowned. The author would later go on to praise GAN applications for their ability to help generate assets for independent artists who are short on budget and manpower.","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":4118,"to":4128}}}}],["c12d2456-f517-48fa-a82b-976d0722dbd7",{"pageContent":"=== Science ===\nGANs can improve astronomical images and simulate gravitational lensing for dark matter research. They were used in 2019 to successfully model the distribution of dark matter in a particular direction in space and to predict the gravitational lensing that will occur.GANs have been proposed as a fast and accurate way of modeling high energy jet formation and modeling showers through calorimeters of high-energy physics experiments. GANs have also been trained to accurately approximate bottlenecks in computationally expensive simulations of particle physics experiments. Applications in the context of present and proposed CERN experiments have demonstrated the potential of these methods for accelerating simulation and/or improving simulation fidelity.","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":4131,"to":4132}}}}],["7d91d5ee-6ef9-492e-ae91-5bdd2fccd3c3",{"pageContent":"=== Video games ===\nIn 2018, GANs reached the video game modding community, as a method of up-scaling low-resolution 2D textures in old video games by recreating them in 4k or higher resolutions via image training, and then down-sampling them to fit the game's native resolution (with results resembling the supersampling method of anti-aliasing). With proper training, GANs provide a clearer and sharper 2D texture image magnitudes higher in quality than the original, while fully retaining the original's level of details, colors, etc. Known examples of extensive GAN usage include Final Fantasy VIII, Final Fantasy IX, Resident Evil REmake HD Remaster, and Max Payne.\n\n\n== AI generated video ==\nArtificial intelligence art for video uses AI to generate video from text as Text-to-Video model\n\n\n=== Audio synthesis ===\n\n\n=== Concerns about malicious applications ===","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":4135,"to":4146}}}}],["05e7cd8a-079b-4e29-84c3-a964a847cdc2",{"pageContent":"=== Audio synthesis ===\n\n\n=== Concerns about malicious applications ===\n\nConcerns have been raised about the potential use of GAN-based human image synthesis for sinister purposes, e.g., to produce fake, possibly incriminating, photographs and videos.\nGANs can be used to generate unique, realistic profile photos of people who do not exist, in order to automate creation of fake social media profiles.In 2019 the state of California considered and passed on October 3, 2019, the bill AB-602, which bans the use of human image synthesis technologies to make fake pornography without the consent of the people depicted, and bill AB-730, which prohibits distribution of manipulated videos of a political candidate within 60 days of an election. Both bills were authored by Assembly member Marc Berman and signed by Governor Gavin Newsom. The laws went into effect in 2020.DARPA's Media Forensics program studies ways to counteract fake media, including fake media produced using GANs.","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":4146,"to":4152}}}}],["f00b64cb-c616-40a5-b1cb-24b4e93f6fad",{"pageContent":"=== Transfer learning ===\nState-of-art transfer learning research use GANs to enforce the alignment of the latent feature space, such as in deep reinforcement learning. This works by feeding the embeddings of the source and target task to the discriminator which tries to guess the context. The resulting loss is then (inversely) backpropagated through the encoder.","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":4155,"to":4156}}}}],["5cd15afd-5680-42c9-81f7-e3235e6ac9ec",{"pageContent":"=== Miscellaneous applications ===\nGAN can be used to detect glaucomatous images helping the early diagnosis which is essential to avoid partial or total loss","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":4159,"to":4160}}}}],["0537d198-b4a1-4e5a-b80b-bd14f64b16c9",{"pageContent":"of vision.GANs that produce photorealistic images can be used to visualize interior design, industrial design, shoes, bags, and clothing items or items for computer games' scenes. Such networks were reported to be used by Facebook.GANs have been used to create forensic facial reconstructions of deceased historical figures.GANs can reconstruct 3D models of objects from images, generate novel objects as 3D point clouds, and model patterns of motion in video.GANs can be used to age face photographs to show how an individual's appearance might change with age.GANs can also be used to inpaint missing features in maps, transfer map styles in cartography or augment street view imagery.Relevance feedback on GANs can be used to generate images and replace image search systems.A variation of the GANs is used in training a network to generate optimal control inputs to nonlinear dynamical systems. Where the discriminatory network is known as a critic that checks the optimality of the solution and the generative network is known as an Adaptive network that generates the optimal control. The critic and adaptive network train each other to approximate a nonlinear optimal","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":4161,"to":4161}}}}],["abf3bb5a-2d86-4c63-bc37-3475369b8870",{"pageContent":"as a critic that checks the optimality of the solution and the generative network is known as an Adaptive network that generates the optimal control. The critic and adaptive network train each other to approximate a nonlinear optimal control.GANs have been used to visualize the effect that climate change will have on specific houses.A GAN model called Speech2Face can reconstruct an image of a person's face after listening to their voice.In 2016 GANs were used to generate new molecules for a variety of protein targets implicated in cancer, inflammation, and fibrosis. In 2019 GAN-generated molecules were validated experimentally all the way into mice.Whereas the majority of GAN applications are in image processing, the work has also been done with time-series data. For example, recurrent GANs (R-GANs) have been used to generate energy data for machine learning.","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":4161,"to":4161}}}}],["f6b6f0c1-4aec-41d3-b8b6-de6308072a2e",{"pageContent":"== History ==","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":4164,"to":4164}}}}],["48bcf3b5-e23d-497e-8672-16e992d03a16",{"pageContent":"In 1991, Juergen Schmidhuber published generative and adversarial neural networks that contest with each other in the form of a zero-sum game, where one network's gain is the other network's loss. The first network is a generative model with stochasticity that models a probability distribution over output patterns. The second network learns by gradient descent to predict the reactions of the environment to these patterns. This was called \"artificial curiosity.\" For modern GANs (2014), the environmental reaction is 1 or 0 depending on whether the first network's output is in a given set.Other people had similar ideas but did not develop them similarly. An idea involving adversarial networks was published in a 2010 blog post by Olli Niemitalo. This idea was never implemented and did not involve stochasticity in the generator and thus was not a generative model. It is now known as a conditional GAN or cGAN. An idea similar to GANs was used to model animal behavior by Li, Gauci and Gross in 2013.Another inspiration for GANs was noise-contrastive estimation, which uses the same loss function as GANs and which Goodfellow studied during his PhD in 2010–2014.","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":4165,"to":4165}}}}],["b0609928-584f-4b18-8a00-798821a8daa1",{"pageContent":"Adversarial machine learning has other uses besides generative modeling and can be applied to models other than neural networks. In control theory, adversarial learning based on neural networks was used in 2006 to train robust controllers in a game theoretic sense, by alternating the iterations between a minimizer policy, the controller, and a maximizer policy, the disturbance.In 2017, a GAN was used for image enhancement focusing on realistic textures rather than pixel-accuracy, producing a higher image quality at high magnification. In 2017, the first faces were generated. These were exhibited in February 2018 at the Grand Palais. Faces generated by StyleGAN in 2019 drew comparisons with Deepfakes.Beginning in 2017, GAN technology began to make its presence felt in the fine arts arena with the appearance of a newly developed implementation which was said to have crossed the threshold of being able to generate unique and appealing abstract paintings, and thus dubbed a \"CAN\", for \"creative adversarial network\". A GAN system was used to create the 2018 painting Edmond de Belamy, which sold for US$432,500. An early 2019 article by members of the original CAN team","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":4166,"to":4166}}}}],["928600d2-9a44-4d4d-9be6-68df8cc18dcc",{"pageContent":"abstract paintings, and thus dubbed a \"CAN\", for \"creative adversarial network\". A GAN system was used to create the 2018 painting Edmond de Belamy, which sold for US$432,500. An early 2019 article by members of the original CAN team discussed further progress with that system, and gave consideration as well to the overall prospects for an AI-enabled art.In May 2019, researchers at Samsung demonstrated a GAN-based system that produces videos of a person speaking, given only a single photo of that person.In August 2019, a large dataset consisting of 12,197 MIDI songs each with paired lyrics and melody alignment was created for neural melody generation from lyrics using conditional GAN-LSTM (refer to sources at GitHub AI Melody Generation from Lyrics).In May 2020, Nvidia researchers taught an AI system (termed \"GameGAN\") to recreate the game of Pac-Man simply by watching it being played.","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":4166,"to":4166}}}}],["57a92e6a-29aa-4f83-8bea-b17e9dacbbf2",{"pageContent":"== References ==\n\n\n== External links ==\nKnight, Will. \"5 Big Predictions for Artificial Intelligence in 2017\". MIT Technology Review. Retrieved January 5, 2017.\nKarras, Tero; Laine, Samuli; Aila, Timo (2018). \"A Style-Based Generator Architecture for Generative Adversarial Networks\". arXiv:1812.04948 [cs.NE].\nThis Person Does Not Exist –  photorealistic images of people who do not exist, generated by StyleGAN\nThis Cat Does Not Exist –  photorealistic images of cats who do not exist, generated by StyleGAN\nWang, Zhengwei; She, Qi; Ward, Tomas E. (2019). \"Generative Adversarial Networks in Computer Vision: A Survey and Taxonomy\". arXiv:1906.01529 [cs.LG].","metadata":{"source":"https://en.wikipedia.org/wiki/Generative_adversarial_network","loc":{"lines":{"from":4169,"to":4177}}}}],["cc45c60f-e324-471d-9e5a-ee0eb71ff774",{"pageContent":"A neural network can refer to either a neural circuit of biological neurons (sometimes also called a biological neural network), or a network of artificial neurons or nodes in the case of an artificial neural network. Artificial neural networks are used for solving artificial intelligence (AI) problems; they model connections of biological neurons as weights between nodes. A positive weight reflects an excitatory connection, while negative values mean inhibitory connections. All inputs are modified by a weight and summed. This activity is referred to as a linear combination. Finally, an activation function controls the amplitude of the output. For example, an acceptable range of output is usually between 0 and 1, or it could be −1 and 1.","metadata":{"source":"https://en.wikipedia.org/wiki/Neural_network","loc":{"lines":{"from":1,"to":1}}}}],["5deaaaee-2eee-4d15-bd53-d1950721dc4a",{"pageContent":"These artificial networks may be used for predictive modeling, adaptive control and applications where they can be trained via a dataset. Self-learning resulting from experience can occur within networks, which can derive conclusions from a complex and seemingly unrelated set of information.","metadata":{"source":"https://en.wikipedia.org/wiki/Neural_network","loc":{"lines":{"from":2,"to":2}}}}],["ab4c6eca-00a8-4375-a725-bc421861eed7",{"pageContent":"== Overview ==\nA biological neural network is composed of a group of chemically connected or functionally associated neurons. A single neuron may be connected to many other neurons and the total number of neurons and connections in a network may be extensive. Connections, called synapses, are usually formed from axons to dendrites, though dendrodendritic synapses and other connections are possible. Apart from electrical signalling, there are other forms of signalling that arise from neurotransmitter diffusion.","metadata":{"source":"https://en.wikipedia.org/wiki/Neural_network","loc":{"lines":{"from":5,"to":6}}}}],["aec57a52-21ba-424e-a167-01a0ae9e2042",{"pageContent":"Artificial intelligence, cognitive modelling, and neural networks are information processing paradigms inspired by how biological neural systems process data. Artificial intelligence and cognitive modelling try to simulate some properties of biological neural networks. In the artificial intelligence field, artificial neural networks have been applied successfully to speech recognition, image analysis and adaptive control, in order to construct software agents (in computer and video games) or autonomous robots.\nHistorically, digital computers evolved from the von Neumann model, and operate via the execution of explicit instructions via access to memory by a number of processors. On the other hand, the origins of neural networks are based on efforts to model information processing in biological systems. Unlike the von Neumann model, neural network computing does not separate memory and processing.","metadata":{"source":"https://en.wikipedia.org/wiki/Neural_network","loc":{"lines":{"from":7,"to":8}}}}],["555d8436-913f-41aa-8ab6-7ab3c678a60b",{"pageContent":"Neural network theory has served to identify better how the neurons in the brain function and provide the basis for efforts to create artificial intelligence.","metadata":{"source":"https://en.wikipedia.org/wiki/Neural_network","loc":{"lines":{"from":9,"to":9}}}}],["0af99e3e-533f-4547-884e-d6eb90a87837",{"pageContent":"== History ==\nThe preliminary theoretical base for contemporary neural networks was independently proposed by Alexander Bain (1873) and William James (1890). In their work, both thoughts and body activity resulted from interactions among neurons within the brain.","metadata":{"source":"https://en.wikipedia.org/wiki/Neural_network","loc":{"lines":{"from":12,"to":13}}}}],["0218efe7-9fc9-4e6d-817e-e9fd59ab6b34",{"pageContent":"For Bain, every activity led to the firing of a certain set of neurons. When activities were repeated, the connections between those neurons strengthened. According to his theory, this repetition was what led to the formation of memory. The general scientific community at the time was skeptical of Bain's theory because it required what appeared to be an inordinate number of neural connections within the brain. It is now apparent that the brain is exceedingly complex and that the same brain “wiring” can handle multiple problems and inputs.\nJames's theory was similar to Bain's, however, he suggested that memories and actions resulted from electrical currents flowing among the neurons in the brain. His model, by focusing on the flow of electrical currents, did not require individual neural connections for each memory or action.","metadata":{"source":"https://en.wikipedia.org/wiki/Neural_network","loc":{"lines":{"from":15,"to":16}}}}],["85e2f42e-0175-4808-b380-6601110ffe74",{"pageContent":"C. S. Sherrington (1898) conducted experiments to test James's theory. He ran electrical currents down the spinal cords of rats. However, instead of demonstrating an increase in electrical current as projected by James, Sherrington found that the electrical current strength decreased as the testing continued over time. Importantly, this work led to the discovery of the concept of habituation.","metadata":{"source":"https://en.wikipedia.org/wiki/Neural_network","loc":{"lines":{"from":17,"to":17}}}}],["4a0fa142-c49f-4dbe-acbb-e8e600c63ef4",{"pageContent":"Wilhelm Lenz (1920) and Ernst Ising (1925) created and analyzed the Ising model which is essentially a non-learning artificial recurrent neural network (RNN) consisting of neuron-like threshold elements. In 1972, Shun'ichi Amari made this architecture adaptive. His learning RNN was popularised by John Hopfield in 1982.McCulloch and Pitts  (1943) also created a computational model for neural networks based on mathematics and algorithms. They called this model threshold logic. These early models paved the way for neural network research to split into two distinct approaches. One approach focused on biological processes in the brain and the other focused on the application of neural networks to artificial intelligence.","metadata":{"source":"https://en.wikipedia.org/wiki/Neural_network","loc":{"lines":{"from":18,"to":18}}}}],["42119328-aa16-4ebc-a471-7b67294949a1",{"pageContent":"In the late 1940s psychologist Donald Hebb  created a hypothesis of learning based on the mechanism of neural plasticity that is now known as Hebbian learning. Hebbian learning is considered to be a 'typical' unsupervised learning rule and its later variants were early models for long term potentiation. These ideas started being applied to computational models in 1948 with Turing's B-type machines.\nFarley and Clark (1954) first used computational machines, then called calculators, to simulate a Hebbian network at MIT. Other neural network computational machines were created by Rochester, Holland, Habit, and Duda (1956).\nFrank Rosenblatt (1958) created the perceptron, an algorithm for pattern recognition based on a two-layer learning computer network using simple addition and subtraction. With mathematical notation, Rosenblatt also described circuitry not in the basic perceptron, such as the exclusive-or circuit.","metadata":{"source":"https://en.wikipedia.org/wiki/Neural_network","loc":{"lines":{"from":19,"to":21}}}}],["80a60158-6bb2-4174-a799-923c4e9c36b3",{"pageContent":"Some say that neural network research stagnated after the publication of machine learning research by Marvin Minsky and Seymour Papert (1969). They discovered two key issues with the computational machines that processed neural networks. The first issue was that single-layer neural networks were incapable of processing the exclusive-or circuit. The second significant issue was that computers were not sophisticated enough to effectively handle the long run time required by large neural networks. However, by the time this book came out, methods for training multilayer perceptrons (MLPs) were already known. The first deep learning MLP was published by Alexey Grigorevich Ivakhnenko and Valentin Lapa in 1965. The first deep learning MLP trained by stochastic gradient descent was published in 1967 by Shun'ichi Amari.","metadata":{"source":"https://en.wikipedia.org/wiki/Neural_network","loc":{"lines":{"from":22,"to":22}}}}],["72108f79-8fe9-4066-89ea-b4015f351e88",{"pageContent":"In computer experiments conducted by Amari's student Saito, a five layer MLP with two modifiable layers learned  useful internal representations to classify non-linearily separable pattern classes.Neural network research was boosted when computers achieved greater processing power. Also key in later advances was the backpropagation algorithm. It is an efficient application of the Leibniz chain rule (1673) to networks of differentiable nodes. It is also known as","metadata":{"source":"https://en.wikipedia.org/wiki/Neural_network","loc":{"lines":{"from":23,"to":23}}}}],["cbfe6543-3be1-4f68-81a0-bef1089840dd",{"pageContent":"the reverse mode of automatic differentiation or reverse accumulation, due to Seppo Linnainmaa (1970). The term \"back-propagating errors\" was introduced in 1962 by Frank Rosenblatt, but he did not have an implementation of this procedure, although Henry J. Kelley had a continuous precursor of backpropagation already in 1960 in the context of control theory. In 1982, Paul Werbos applied backpropagation to MLPs in the way that has become standard.In the late 1970s to early 1980s, interest briefly emerged in theoretically investigating the Ising model by Wilhelm Lenz (1920) and Ernst Ising (1925)","metadata":{"source":"https://en.wikipedia.org/wiki/Neural_network","loc":{"lines":{"from":24,"to":24}}}}],["2ef3a7ef-0c8d-4024-af38-09fad977806e",{"pageContent":"in relation to Cayley tree topologies and large neural networks. In 1981, the Ising model was solved exactly for the general case of closed Cayley trees (with loops) with an arbitrary branching ratio and found to exhibit unusual phase transition behavior in its local-apex and long-range site-site correlations.The parallel distributed processing of the mid-1980s became popular under the name connectionism. The text by Rumelhart and McClelland (1986) provided a full exposition on the use of connectionism in computers to simulate neural processes.\nNeural networks, as used in artificial intelligence, have traditionally been viewed as simplified models of neural processing in the brain, even though the relation between this model and brain biological architecture is debated, as it is not clear to what degree artificial neural networks mirror brain function.","metadata":{"source":"https://en.wikipedia.org/wiki/Neural_network","loc":{"lines":{"from":25,"to":26}}}}],["b7826b39-ce9f-46a4-bdcc-887bc381b823",{"pageContent":"== Artificial intelligence ==","metadata":{"source":"https://en.wikipedia.org/wiki/Neural_network","loc":{"lines":{"from":29,"to":29}}}}],["66e6f71e-26c7-48a3-b7ea-b8e02dead4c7",{"pageContent":"A neural network (NN), in the case of artificial neurons called artificial neural network (ANN) or simulated neural network (SNN), is an interconnected group of natural or artificial neurons that uses a mathematical or computational model for information processing based on a connectionistic approach to computation. In most cases an ANN is an adaptive system that changes its structure based on external or internal information that flows through the network.\nIn more practical terms neural networks are non-linear statistical data modeling or decision making tools. They can be used to model complex relationships between inputs and outputs or to find patterns in data.","metadata":{"source":"https://en.wikipedia.org/wiki/Neural_network","loc":{"lines":{"from":31,"to":32}}}}],["3c122da6-b11d-450f-bd98-7860d565daf9",{"pageContent":"An artificial neural network involves a network of simple processing elements (artificial neurons) which can exhibit complex global behavior, determined by the connections between the processing elements and element parameters. Artificial neurons were first proposed in 1943 by Warren McCulloch, a neurophysiologist, and Walter Pitts, a logician, who first collaborated at the University of Chicago.One classical type of artificial neural network is the recurrent Hopfield network.","metadata":{"source":"https://en.wikipedia.org/wiki/Neural_network","loc":{"lines":{"from":33,"to":33}}}}],["6b4dfb24-a9f6-4a81-983b-6a4dc210a1cb",{"pageContent":"The concept of a neural network appears to have first been proposed by Alan Turing in his 1948 paper Intelligent Machinery in which he called them \"B-type unorganised machines\".The utility of artificial neural network models lies in the fact that they can be used to infer a function from observations and also to use it. Unsupervised neural networks can also be used to learn representations of the input that capture the salient characteristics of the input distribution, e.g., see the Boltzmann machine (1983), and more recently, deep learning algorithms, which can implicitly learn the distribution function of the observed data. Learning in neural networks is particularly useful in applications where the complexity of the data or task makes the design of such functions by hand impractical.","metadata":{"source":"https://en.wikipedia.org/wiki/Neural_network","loc":{"lines":{"from":34,"to":34}}}}],["bdd21d99-1afa-4b60-b319-6455ef017fad",{"pageContent":"== Applications ==\nNeural networks can be used in different fields. The tasks to which artificial neural networks are applied tend to fall within the following broad categories:","metadata":{"source":"https://en.wikipedia.org/wiki/Neural_network","loc":{"lines":{"from":37,"to":38}}}}],["5ff66022-2fab-40ed-adb5-d3612b216b7b",{"pageContent":"Function approximation, or regression analysis, including time series prediction and modeling.\nClassification, including pattern and sequence recognition, novelty detection and sequential decision making.\nData processing, including filtering, clustering, blind signal separation and compression.Application areas of ANNs include nonlinear system identification and control (vehicle control, process control), game-playing and decision making (backgammon, chess, racing), pattern recognition (radar systems, face identification, object recognition), sequence recognition (gesture, speech, handwritten text recognition), medical diagnosis, financial applications, data mining (or knowledge discovery in databases, \"KDD\"), visualization and e-mail spam filtering. For example, it is possible to create a semantic profile of user's interests emerging from pictures trained for object recognition.","metadata":{"source":"https://en.wikipedia.org/wiki/Neural_network","loc":{"lines":{"from":40,"to":42}}}}],["702442c3-08a8-4eb9-a7b9-be4fb7e6d65e",{"pageContent":"== Neuroscience ==\nTheoretical and computational neuroscience is the field concerned with the analysis and computational modeling of biological neural systems.\nSince neural systems are intimately related to cognitive processes and behaviour, the field is closely related to cognitive and behavioural modeling.\nThe aim of the field is to create models of biological neural systems in order to understand how biological systems work. To gain this understanding, neuroscientists strive to make a link between observed biological processes (data), biologically plausible mechanisms for neural processing and learning (biological neural network models) and theory (statistical learning theory and information theory).","metadata":{"source":"https://en.wikipedia.org/wiki/Neural_network","loc":{"lines":{"from":45,"to":48}}}}],["9dd26ac4-f379-4ff5-8d8e-c0fda6cff56a",{"pageContent":"=== Types of models ===\nMany models are used; defined at different levels of abstraction, and modeling different aspects of neural systems. They range from models of the short-term behaviour of individual neurons, through models of the dynamics of neural circuitry arising from interactions between individual neurons, to models of behaviour arising from abstract neural modules that represent complete subsystems. These include models of the long-term and short-term plasticity of neural systems and its relation to learning and memory, from the individual neuron to the system level.\n\n\n=== Connectivity ===","metadata":{"source":"https://en.wikipedia.org/wiki/Neural_network","loc":{"lines":{"from":51,"to":55}}}}],["ce5ecc37-4357-4f3a-aac1-568c0f4115db",{"pageContent":"=== Connectivity ===\n\nIn August 2020 scientists reported that bi-directional connections, or added appropriate feedback connections, can accelerate and improve communication between and in modular neural networks of the brain's cerebral cortex and lower the threshold for their successful communication. They showed that adding feedback connections between a resonance pair can support successful propagation of a single pulse packet throughout the entire network.","metadata":{"source":"https://en.wikipedia.org/wiki/Neural_network","loc":{"lines":{"from":55,"to":57}}}}],["f384d39f-a77e-4442-842a-34227f9f1c5e",{"pageContent":"== Criticism ==","metadata":{"source":"https://en.wikipedia.org/wiki/Neural_network","loc":{"lines":{"from":60,"to":60}}}}],["7552a3e2-3181-440c-9938-65e45196adb1",{"pageContent":"Historically, a common criticism of neural networks, particularly in robotics, was that they require a large diversity of training samples for real-world operation. This is not surprising, since any learning machine needs sufficient representative examples in order to capture the underlying structure that allows it to generalize to new cases. Dean Pomerleau, in his research presented in the paper \"Knowledge-based Training of Artificial Neural Networks for Autonomous Robot Driving,\" uses a neural network to train a robotic vehicle to drive on multiple types of roads (single lane, multi-lane, dirt, etc.). A large amount of his research is devoted to (1) extrapolating multiple training scenarios from a single training experience, and (2) preserving past training diversity so that the system does not become overtrained (if, for example, it is presented with a series of right turns—it should not learn to always turn right). These issues are common in neural networks that must decide from amongst a wide variety of responses, but can be dealt with in several ways, for example by randomly shuffling the training examples, by using a numerical optimization algorithm that","metadata":{"source":"https://en.wikipedia.org/wiki/Neural_network","loc":{"lines":{"from":61,"to":61}}}}],["02d9bc52-8c91-4d88-87c6-80881c9ba54e",{"pageContent":"are common in neural networks that must decide from amongst a wide variety of responses, but can be dealt with in several ways, for example by randomly shuffling the training examples, by using a numerical optimization algorithm that does not take too large steps when changing the network connections following an example, or by grouping examples in so-called mini-batches.","metadata":{"source":"https://en.wikipedia.org/wiki/Neural_network","loc":{"lines":{"from":61,"to":61}}}}],["3c5f07fa-6a68-48d0-b5d8-da7d5808c530",{"pageContent":"A. K. Dewdney, a former Scientific American columnist, wrote in 1997, \"Although neural nets do solve a few toy problems, their powers of computation are so limited that I am surprised anyone takes them seriously as a general problem-solving tool.\"Arguments for Dewdney's position are that to implement large and effective software neural networks, much processing and storage resources need to be committed. While the brain has hardware tailored to the task of processing signals through a graph of neurons, simulating even a most simplified form on Von Neumann technology may compel a neural network designer to fill many millions of database rows for its connections—which can consume vast amounts of computer memory and data storage capacity. Furthermore, the designer of neural network systems will often need to simulate the transmission of signals through many of these connections and their associated neurons—which must often be matched with incredible amounts of CPU processing power and time. While neural networks often yield effective programs, they too often do so at the cost of efficiency (they tend to consume considerable amounts of time and money).","metadata":{"source":"https://en.wikipedia.org/wiki/Neural_network","loc":{"lines":{"from":62,"to":62}}}}],["8f033cad-574d-4611-9aa1-514a233fe835",{"pageContent":"Arguments against Dewdney's position are that neural nets have been successfully used to solve many complex and diverse tasks, such as autonomously flying aircraft.Technology writer Roger Bridgman commented on Dewdney's statements about neural nets:","metadata":{"source":"https://en.wikipedia.org/wiki/Neural_network","loc":{"lines":{"from":63,"to":63}}}}],["476f33b9-bcc8-47bf-89cc-811f8de5b42c",{"pageContent":"Neural networks, for instance, are in the dock not only because they have been hyped to high heaven, (what hasn't?) but also because you could create a successful net without understanding how it worked: the bunch of numbers that captures its behaviour would in all probability be \"an opaque, unreadable table...valueless as a scientific resource\".\nIn spite of his emphatic declaration that science is not technology, Dewdney seems here to pillory neural nets as bad science when most of those devising them are just trying to be good engineers. An unreadable table that a useful machine could read would still be well worth having.","metadata":{"source":"https://en.wikipedia.org/wiki/Neural_network","loc":{"lines":{"from":65,"to":66}}}}],["ae474af1-7250-4603-8058-5e999c34862e",{"pageContent":"Although it is true that analyzing what has been learned by an artificial neural network is difficult, it is much easier to do so than to analyze what has been learned by a biological neural network. Moreover, recent emphasis on the explainability of AI has contributed towards the development of methods, notably those based on attention mechanisms, for visualizing and explaining learned neural networks. Furthermore, researchers involved in exploring learning algorithms for neural networks are gradually uncovering generic principles that allow a learning machine to be successful. For example, Bengio and LeCun (2007) wrote an article regarding local vs non-local learning, as well as shallow vs deep architecture.Some other criticisms came from believers of hybrid models (combining neural networks and symbolic approaches). They advocate the intermix of these two approaches and believe that hybrid models can better capture the mechanisms of the human mind (Sun and Bookman, 1990).","metadata":{"source":"https://en.wikipedia.org/wiki/Neural_network","loc":{"lines":{"from":68,"to":68}}}}],["e7649a09-b6de-4ac7-9e1f-bc7d66efdd31",{"pageContent":"== Recent improvements ==","metadata":{"source":"https://en.wikipedia.org/wiki/Neural_network","loc":{"lines":{"from":71,"to":71}}}}],["d34cf2c7-30c0-4f97-b00b-3a19d04d6446",{"pageContent":"While initially research had been concerned mostly with the electrical characteristics of neurons, a particularly important part of the investigation in recent years has been the exploration of the role of neuromodulators such as dopamine, acetylcholine, and serotonin on behaviour and learning.Biophysical models, such as BCM theory, have been important in understanding mechanisms for synaptic plasticity, and have had applications in both computer science and neuroscience. Research is ongoing in understanding the computational algorithms used in the brain, with some recent biological evidence for radial basis networks and neural backpropagation as mechanisms for processing data.Computational devices have been created in CMOS for both biophysical simulation and neuromorphic computing. More recent efforts show promise for creating nanodevices for very large scale principal components analyses and convolution. If successful, these efforts could usher in a new era of neural computing that is a step beyond digital computing, because it depends on learning rather than programming and because it is fundamentally analog rather than digital even though","metadata":{"source":"https://en.wikipedia.org/wiki/Neural_network","loc":{"lines":{"from":72,"to":72}}}}],["dc25c55d-964e-423c-b4ca-79c6148762a5",{"pageContent":"successful, these efforts could usher in a new era of neural computing that is a step beyond digital computing, because it depends on learning rather than programming and because it is fundamentally analog rather than digital even though the first instantiations may in fact be with CMOS digital devices.","metadata":{"source":"https://en.wikipedia.org/wiki/Neural_network","loc":{"lines":{"from":72,"to":72}}}}],["436d697a-5036-4b35-9b7f-bfa9f60997b3",{"pageContent":"Between 2009 and 2012, the recurrent neural networks and deep feedforward neural networks developed in the research group of Jürgen Schmidhuber at the Swiss AI Lab IDSIA have won eight international competitions in pattern recognition and machine learning. For example, multi-dimensional long short term memory (LSTM) won three competitions in connected handwriting recognition at the 2009 International Conference on Document Analysis and Recognition (ICDAR), without any prior knowledge about the three different languages to be learned.\nVariants of the back-propagation algorithm as well as unsupervised methods by Geoff Hinton and colleagues at the University of Toronto can be used to train deep, highly nonlinear neural architectures, similar to the 1980 Neocognitron by Kunihiko Fukushima, and the \"standard architecture of vision\", inspired by the simple and complex cells identified by David H. Hubel and Torsten Wiesel in the primary visual cortex.","metadata":{"source":"https://en.wikipedia.org/wiki/Neural_network","loc":{"lines":{"from":73,"to":74}}}}],["28710122-bdab-47d9-8ab4-15a66c0678af",{"pageContent":"Radial basis function and wavelet networks have also been introduced. These can be shown to offer best approximation properties and have been applied in nonlinear system identification and classification applications.Deep learning feedforward networks alternate convolutional layers and max-pooling layers, topped by several pure classification layers. Fast GPU-based implementations of this approach have won several pattern recognition contests, including the IJCNN 2011 Traffic Sign Recognition Competition and the  ISBI 2012 Segmentation of Neuronal Structures in Electron Microscopy Stacks challenge. Such neural networks also were the first artificial pattern recognizers to achieve human-competitive or even superhuman performance on benchmarks such as traffic sign recognition (IJCNN 2012), or the MNIST handwritten digits problem of Yann LeCun and colleagues at NYU.","metadata":{"source":"https://en.wikipedia.org/wiki/Neural_network","loc":{"lines":{"from":75,"to":75}}}}],["5151c2f2-0d9e-4606-9a98-1111a406dcbf",{"pageContent":"Analytical and computational techniques derived from statistical physics of disordered systems, can be extended to large-scale problems, including machine learning, e.g., to analyze the weight space of deep neural networks.","metadata":{"source":"https://en.wikipedia.org/wiki/Neural_network","loc":{"lines":{"from":76,"to":76}}}}],["6888e155-619a-4725-8a32-4c55ab499705",{"pageContent":"== See also ==\n\n\n== References ==\n\n\n== External links ==\n\nA Brief Introduction to Neural Networks (D. Kriesel) - Illustrated, bilingual manuscript about artificial neural networks; Topics so far: Perceptrons, Backpropagation, Radial Basis Functions, Recurrent Neural Networks, Self Organizing Maps, Hopfield Networks.\nReview of Neural Networks in Materials Science\nArtificial Neural Networks Tutorial in three languages (Univ. Politécnica de Madrid)\nAnother introduction to ANN\nNext Generation of Neural Networks - Google Tech Talks\nPerformance of Neural Networks\nNeural Networks and Information\nSanderson, Grant (October 5, 2017). \"But what is a Neural Network?\". 3Blue1Brown. Archived from the original on November 7, 2021 – via YouTube.","metadata":{"source":"https://en.wikipedia.org/wiki/Neural_network","loc":{"lines":{"from":79,"to":94}}}}]],{"0":"60f3226f-f447-4c23-9c37-db001113bb79","1":"73e65637-a6e8-4f4c-bd90-b7518c3261c8","2":"fb97d150-f31a-4f44-b941-3f8315c3a816","3":"65974fa5-1750-4573-94c4-4f059a65647d","4":"bbcb70df-bfa1-4506-b372-26a66b88a8f1","5":"b930acf7-4373-4670-babe-ac7b5a46028d","6":"cccb7dcd-7476-4a00-9d37-799ce6d89504","7":"124dbacd-055d-4ec7-bb3f-e328fed84868","8":"8d9205e3-3a99-4072-bf27-6b7ad7d4031d","9":"dc59c82c-4fa0-4c35-b4fe-dc8515405240","10":"5f3bdfa1-2799-4153-bb28-818e666a9fa0","11":"94962890-afdc-4976-9d6d-cd0c30372152","12":"a4871728-badd-4266-867d-c1c9af7344f2","13":"a223b309-ab2f-4c7e-924e-369932a1d963","14":"4d0f93ab-8b2a-4b72-b093-62cd746b0e21","15":"fc734936-19b5-4a08-a854-4881a5d4f2ff","16":"d45d051e-35f3-43ec-a070-8e270d421973","17":"71778adf-0451-46c7-a29d-597c0b26eda5","18":"b6a288d1-5e41-4a5c-9168-abd74fef2174","19":"595b50f9-1aa2-420e-87ac-92247a0278d2","20":"5dc07edd-6678-4741-b201-83da58e5d18d","21":"40d16d40-c6b5-4dd4-9d7b-7c3e145bffb6","22":"b5cacc6b-5e76-4e7d-9b1d-0f330fc519c0","23":"93320cb9-e13c-4604-8d0b-51d316861448","24":"56d278d0-1296-4441-91b4-b7af6771115b","25":"1aa5138c-8d98-4e27-aa1c-da769836e896","26":"cfd8f153-22c0-4cec-a9de-75ca4ca42314","27":"629b2565-28fe-4068-8d58-9adf2b2cf457","28":"2cbbb28f-f3b4-4f90-bf67-286bfef326b7","29":"dec4fe99-5be3-46c0-adc0-626e4b5f51ae","30":"729f83ef-59d8-438d-adc4-97b3af27ab4c","31":"67007ab0-9000-4889-85eb-deadaaf595be","32":"4dfc9577-f20e-4084-b7c2-4a1dd7ee1e05","33":"f2d56c05-3cf6-4d5a-9112-a42e95eee3f1","34":"5e9da455-e6bf-4bf1-8023-16bb0e2b231d","35":"4fbe0546-f361-4c02-a5d8-67d520afc25c","36":"7581a925-65ae-46c8-b734-61e485c29be9","37":"90fb1ffd-5750-43ec-9b49-f39e0fdf27f3","38":"f1dc7eec-6df7-4d90-9c14-65e33c6f43be","39":"d31f6f76-9e2b-466d-8a0e-656cab4378a9","40":"7d412bed-b6ab-411f-afff-bcd24410f17b","41":"51db6166-81a2-4fc1-9711-d968525f6892","42":"d4b59f05-fb09-4d1d-aa7d-3ebde61cae3d","43":"4565dc93-8b71-4ff8-8443-1f9045849128","44":"987fd1dc-e610-49a6-82ac-1af8502b44db","45":"b2100385-5297-40c5-8f49-72d80e8033d4","46":"97736f7b-d897-4401-8306-90f6720de07d","47":"d1f3861a-6965-4b51-81df-1e5eb2097fb4","48":"fdffe069-cbb0-444c-876c-b189c9e60f98","49":"240e3454-d170-4d3e-85ad-2fad88bd15f9","50":"511ce78e-24ab-420e-8154-f9e6e0a6e77d","51":"124b4349-3d6f-473c-83d3-08aa4491005f","52":"77de065d-fd9e-4d16-9191-4e559729c470","53":"8cf1f948-dcc4-408c-9525-a24e6a80657c","54":"6c941b70-fede-4f78-9a5a-45ffe67de90a","55":"2c3c9098-7d1a-4254-995c-2d4aac177b79","56":"22b5baa6-e460-4f81-b496-0ebe45bb52ac","57":"275aaf2d-919d-4dc0-872d-fba9c8f8d040","58":"b4093a73-aec9-454b-89ed-aa3b17421958","59":"c125541d-604d-44b3-b7cb-281b284bfd77","60":"beef4eab-2b06-4342-bfae-d41815682104","61":"67d8e333-8f90-4189-9998-4549cba584a9","62":"a24759ba-bc1d-4fa3-bbfc-85f318cf1dc4","63":"d6c693f7-e022-4d8d-9ee8-61d92df469c0","64":"32480df5-bbb6-4a4f-abf8-5beaf03b16d1","65":"283df040-3d7e-4388-8cde-7452cd10e1cf","66":"920b767a-6f41-4987-b344-c133d50a38a3","67":"68d300b7-9cb6-4d08-93e5-d46d2170d770","68":"12446534-af55-4af5-b2df-ef67c96d472e","69":"9cc885b6-b74a-4b87-911d-eb6b2ff31b12","70":"ac9ee6c1-6bf3-4fd9-af5b-b774a41aef73","71":"c17fef1f-8cae-4dbd-b6c9-6978a6d2b6b1","72":"54c1e592-8d0a-474b-9170-eee3beed4b45","73":"f8106908-880d-42d0-8df6-ac3eaa05393d","74":"350a59ce-987e-4b9b-a450-e9be0679e6c9","75":"4515d2e3-8059-403d-8467-f7c470fd0d6f","76":"6e63e013-a01b-4063-bc8a-604a4a963cc2","77":"0d80b4b9-6d25-418e-87d1-e017fa30a622","78":"62f2cdec-8ee5-468a-abcb-e763f7b3a1aa","79":"e8cc3e5a-bd7e-4fe6-a4a6-3ae1177e6266","80":"ae69eda5-eda2-4f36-a354-7ef1d93c14e2","81":"f5293f10-eb3f-42d5-ae5c-1a037a6ec896","82":"62a77461-9847-4cb4-86bf-4c0d6b651cee","83":"e1623328-ad8b-44ef-b3e1-91370db4fee6","84":"5c51cad3-b62a-445f-9f01-c25c205bc948","85":"21bbe001-6d5a-42fd-a36a-89f7c958e942","86":"cd45e0dd-f6de-4802-935d-f8253a8d0294","87":"5709dffb-b818-416e-9143-7527093f9370","88":"68e27d57-0e6b-4416-b7d3-fd3c2da49b2b","89":"4d78f4b3-ccc3-491e-aeef-28f521fa2165","90":"ff95771e-54c4-49ff-9ed6-69920c2a8e2a","91":"a865e460-86db-46ac-9d73-75646fa17203","92":"71250f02-8b8e-4e10-aae0-a41207acf658","93":"658ed410-8a80-483b-981d-16618ec50cc1","94":"45171cb7-b1c5-4f2e-89fa-1327301c815a","95":"6a1fdd95-0164-45c3-8f6a-468fb9bdeb4e","96":"fd267167-a3cd-4818-a0ac-d59f3f6d6f94","97":"8f0e3a75-9b50-465e-a42a-04a337200b74","98":"2614f9ce-f5b6-45a1-b539-106fdb0a0474","99":"1ac320b7-a833-4124-ba0d-812bae285ad6","100":"80ca790e-e188-4452-a187-09cc81e152f5","101":"36470f2b-3c1b-4af4-a07e-7459c7d0cd65","102":"0303f857-6342-40e3-9e81-9b58b91b8151","103":"c12d2456-f517-48fa-a82b-976d0722dbd7","104":"7d91d5ee-6ef9-492e-ae91-5bdd2fccd3c3","105":"05e7cd8a-079b-4e29-84c3-a964a847cdc2","106":"f00b64cb-c616-40a5-b1cb-24b4e93f6fad","107":"5cd15afd-5680-42c9-81f7-e3235e6ac9ec","108":"0537d198-b4a1-4e5a-b80b-bd14f64b16c9","109":"abf3bb5a-2d86-4c63-bc37-3475369b8870","110":"f6b6f0c1-4aec-41d3-b8b6-de6308072a2e","111":"48bcf3b5-e23d-497e-8672-16e992d03a16","112":"b0609928-584f-4b18-8a00-798821a8daa1","113":"928600d2-9a44-4d4d-9be6-68df8cc18dcc","114":"57a92e6a-29aa-4f83-8bea-b17e9dacbbf2","115":"cc45c60f-e324-471d-9e5a-ee0eb71ff774","116":"5deaaaee-2eee-4d15-bd53-d1950721dc4a","117":"ab4c6eca-00a8-4375-a725-bc421861eed7","118":"aec57a52-21ba-424e-a167-01a0ae9e2042","119":"555d8436-913f-41aa-8ab6-7ab3c678a60b","120":"0af99e3e-533f-4547-884e-d6eb90a87837","121":"0218efe7-9fc9-4e6d-817e-e9fd59ab6b34","122":"85e2f42e-0175-4808-b380-6601110ffe74","123":"4a0fa142-c49f-4dbe-acbb-e8e600c63ef4","124":"42119328-aa16-4ebc-a471-7b67294949a1","125":"80a60158-6bb2-4174-a799-923c4e9c36b3","126":"72108f79-8fe9-4066-89ea-b4015f351e88","127":"cbfe6543-3be1-4f68-81a0-bef1089840dd","128":"2ef3a7ef-0c8d-4024-af38-09fad977806e","129":"b7826b39-ce9f-46a4-bdcc-887bc381b823","130":"66e6f71e-26c7-48a3-b7ea-b8e02dead4c7","131":"3c122da6-b11d-450f-bd98-7860d565daf9","132":"6b4dfb24-a9f6-4a81-983b-6a4dc210a1cb","133":"bdd21d99-1afa-4b60-b319-6455ef017fad","134":"5ff66022-2fab-40ed-adb5-d3612b216b7b","135":"702442c3-08a8-4eb9-a7b9-be4fb7e6d65e","136":"9dd26ac4-f379-4ff5-8d8e-c0fda6cff56a","137":"ce5ecc37-4357-4f3a-aac1-568c0f4115db","138":"f384d39f-a77e-4442-842a-34227f9f1c5e","139":"7552a3e2-3181-440c-9938-65e45196adb1","140":"02d9bc52-8c91-4d88-87c6-80881c9ba54e","141":"3c5f07fa-6a68-48d0-b5d8-da7d5808c530","142":"8f033cad-574d-4611-9aa1-514a233fe835","143":"476f33b9-bcc8-47bf-89cc-811f8de5b42c","144":"ae474af1-7250-4603-8058-5e999c34862e","145":"e7649a09-b6de-4ac7-9e1f-bc7d66efdd31","146":"d34cf2c7-30c0-4f97-b00b-3a19d04d6446","147":"dc25c55d-964e-423c-b4ca-79c6148762a5","148":"436d697a-5036-4b35-9b7f-bfa9f60997b3","149":"28710122-bdab-47d9-8ab4-15a66c0678af","150":"5151c2f2-0d9e-4606-9a98-1111a406dcbf","151":"6888e155-619a-4725-8a32-4c55ab499705"}]